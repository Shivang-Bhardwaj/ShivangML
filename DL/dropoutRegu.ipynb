{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.0701</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>0.1523</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.0834</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>0.2002</td>\n",
       "      <td>0.2876</td>\n",
       "      <td>0.3674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0659</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0612</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.1107</td>\n",
       "      <td>0.0973</td>\n",
       "      <td>0.0751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>0.1618</td>\n",
       "      <td>0.2558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.1218</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>0.1229</td>\n",
       "      <td>0.2119</td>\n",
       "      <td>0.2531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "92   0.0260  0.0192  0.0254  0.0061  0.0352  0.0701  0.1263  0.1080  0.1523   \n",
       "89   0.0235  0.0291  0.0749  0.0519  0.0227  0.0834  0.0677  0.2002  0.2876   \n",
       "73   0.0139  0.0222  0.0089  0.0108  0.0215  0.0136  0.0659  0.0954  0.0786   \n",
       "53   0.0293  0.0378  0.0257  0.0062  0.0130  0.0612  0.0895  0.1107  0.0973   \n",
       "179  0.0394  0.0420  0.0446  0.0551  0.0597  0.1416  0.0956  0.0802  0.1618   \n",
       "122  0.0249  0.0119  0.0277  0.0760  0.1218  0.1538  0.1192  0.1229  0.2119   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "92   0.1630  ...  0.0118  0.0120  0.0051  0.0070  0.0015  0.0035  0.0008   \n",
       "89   0.3674  ...  0.0083  0.0037  0.0095  0.0105  0.0030  0.0132  0.0068   \n",
       "73   0.1015  ...  0.0062  0.0072  0.0113  0.0012  0.0022  0.0025  0.0059   \n",
       "53   0.0751  ...  0.0065  0.0072  0.0108  0.0051  0.0102  0.0041  0.0055   \n",
       "179  0.2558  ...  0.0146  0.0040  0.0114  0.0032  0.0062  0.0101  0.0068   \n",
       "122  0.2531  ...  0.0027  0.0068  0.0150  0.0012  0.0133  0.0048  0.0244   \n",
       "\n",
       "         58      59  60  \n",
       "92   0.0044  0.0077   R  \n",
       "89   0.0108  0.0090   R  \n",
       "73   0.0039  0.0048   R  \n",
       "53   0.0050  0.0087   R  \n",
       "179  0.0053  0.0087   M  \n",
       "122  0.0077  0.0074   M  \n",
       "\n",
       "[6 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'C:\\Users\\DELL PC\\Desktop\\ML\\DL\\useful_data\\solardata.csv',header=None)\n",
    "df.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "     ..\n",
       "56    0\n",
       "57    0\n",
       "58    0\n",
       "59    0\n",
       "60    0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "            34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "            51, 52, 53, 54, 55, 56, 57, 58, 59, 60],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     97\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(60,axis='columns')\n",
    "y=df[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     R\n",
       "126  0\n",
       "150  0\n",
       "17   1\n",
       "62   1\n",
       "143  0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=pd.get_dummies(y,drop_first=True)\n",
    "y.sample(5)  #R--> 1 and M--> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R\n",
       "0    111\n",
       "1     97\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.25,random_state=58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((156, 60), (52, 60))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.5192\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6677 - accuracy: 0.6282\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6428 - accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.7436\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5891 - accuracy: 0.7436\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7885\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7885\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7756\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7564\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.8077\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.8077\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.8013\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8205\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8526\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.8397\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8205\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3187 - accuracy: 0.8590\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8782\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3164 - accuracy: 0.8397\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2733 - accuracy: 0.9038\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.8782\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2445 - accuracy: 0.9103\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.9167\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2652 - accuracy: 0.8718\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2374 - accuracy: 0.9103\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.8782\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2274 - accuracy: 0.8718\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1820 - accuracy: 0.9423\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1997 - accuracy: 0.9359\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1810 - accuracy: 0.9487\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9359\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1525 - accuracy: 0.9615\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1542 - accuracy: 0.9487\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1447 - accuracy: 0.9615\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1528 - accuracy: 0.9551\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1295 - accuracy: 0.9615\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.9551\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1133 - accuracy: 0.9615\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1043 - accuracy: 0.9744\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1091 - accuracy: 0.9744\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1408 - accuracy: 0.9487\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0866 - accuracy: 0.9808\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0855 - accuracy: 0.9808\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.9936\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9936\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0881 - accuracy: 0.9679\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0973 - accuracy: 0.9808\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0901 - accuracy: 0.9744\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9936\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9936\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.9872\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9936\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.9936\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.9936\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.9936\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x228dac82f10>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=tf.keras.Sequential([\n",
    "    keras.layers.Dense(60,input_dim=60,activation='relu'),\n",
    "    keras.layers.Dense(30,activation='relu'),\n",
    "    keras.layers.Dense(15,activation='relu'),\n",
    "    keras.layers.Dense(1,input_dim=60,activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train,y_train,epochs=100,batch_size=8)  #batch_size: no of sample in a batch given to mini batch gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x00000228D911A3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.9038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5267820954322815, 0.9038461446762085]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.9708974e-01 7.1468949e-04 6.2194467e-04 7.4620007e-06 7.8934117e-06\n",
      " 4.2985678e-03 1.2484193e-04 8.8029021e-01 3.7117043e-01 1.3492912e-02]\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test).reshape(-1)\n",
    "print(y_pred[:10])\n",
    "\n",
    "y_pred=np.round(y_pred) #round off the value to nearest integer 0 or 1\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     R\n",
       "78   1\n",
       "173  0\n",
       "100  0\n",
       "181  0\n",
       "202  0\n",
       "112  0\n",
       "206  0\n",
       "68   1\n",
       "164  0\n",
       "114  0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92        32\n",
      "           1       0.89      0.85      0.87        20\n",
      "\n",
      "    accuracy                           0.90        52\n",
      "   macro avg       0.90      0.89      0.90        52\n",
      "weighted avg       0.90      0.90      0.90        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 2ms/step - loss: 0.7781 - accuracy: 0.5256\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7201 - accuracy: 0.4679\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7110 - accuracy: 0.4808\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6898 - accuracy: 0.5321\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6814 - accuracy: 0.5385\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.5449\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7212 - accuracy: 0.4744\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6770 - accuracy: 0.5833\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6820 - accuracy: 0.5641\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6669 - accuracy: 0.5705\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6675 - accuracy: 0.6218\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6818 - accuracy: 0.5705\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.5513\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6632 - accuracy: 0.6538\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6785 - accuracy: 0.5449\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6673 - accuracy: 0.5641\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.7308\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6429 - accuracy: 0.6538\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6548 - accuracy: 0.6538\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.6538\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6121 - accuracy: 0.6603\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6200 - accuracy: 0.6410\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.6667\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5726 - accuracy: 0.7179\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.6987\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7756\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5627 - accuracy: 0.7179\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5627 - accuracy: 0.7051\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.6923\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5421 - accuracy: 0.7500\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.7756\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7244\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.8141\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7628\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7628\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7564\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7500\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8077\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.7821\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8141\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8013\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.8013\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7949\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7756\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.8718\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8526\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3587 - accuracy: 0.8846\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8397\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8397\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8462\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8654\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.8077\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3735 - accuracy: 0.8526\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8654\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3274 - accuracy: 0.8974\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3551 - accuracy: 0.8462\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3299 - accuracy: 0.8782\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.8333\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8782\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3186 - accuracy: 0.8782\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3521 - accuracy: 0.8654\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2711 - accuracy: 0.8846\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3331 - accuracy: 0.8526\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3049 - accuracy: 0.8910\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2909 - accuracy: 0.8846\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3019 - accuracy: 0.8590\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3043 - accuracy: 0.8782\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3125 - accuracy: 0.8782\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3339 - accuracy: 0.8654\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3012 - accuracy: 0.8846\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2920 - accuracy: 0.8782\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3061 - accuracy: 0.8718\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3041 - accuracy: 0.9038\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2937 - accuracy: 0.9038\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3099 - accuracy: 0.9167\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2358 - accuracy: 0.9103\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2673 - accuracy: 0.9231\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3078 - accuracy: 0.8654\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2573 - accuracy: 0.9038\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2597 - accuracy: 0.9103\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2747 - accuracy: 0.8974\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2411 - accuracy: 0.8974\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2432 - accuracy: 0.9038\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2282 - accuracy: 0.9295\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1976 - accuracy: 0.9295\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9359\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2180 - accuracy: 0.9295\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.9038\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9167\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2244 - accuracy: 0.9103\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1856 - accuracy: 0.9487\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1848 - accuracy: 0.9487\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2358 - accuracy: 0.8974\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9295\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1966 - accuracy: 0.9295\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1810 - accuracy: 0.9295\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3143 - accuracy: 0.8782\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2587 - accuracy: 0.8846\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x228d761ffa0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_d=tf.keras.Sequential([\n",
    "    keras.layers.Dense(60,input_dim=60,activation='relu'),\n",
    "    keras.layers.Dropout(.5),    #50% neurons are dropped out\n",
    "    keras.layers.Dense(30,activation='relu'),\n",
    "    keras.layers.Dropout(.4),\n",
    "    keras.layers.Dense(15,activation='relu'),\n",
    "    keras.layers.Dropout(.4),\n",
    "    keras.layers.Dense(1,input_dim=60,activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_d.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_d.fit(X_train,y_train,epochs=100,batch_size=8)\n",
    "\n",
    "\n",
    "# rule put Dropout layer after Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4048081040382385, 0.8461538553237915]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_d.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "y_pred=model_d.predict(X_test).ravel()\n",
    "y_pred[:5]\n",
    "y_pred=np.round(y_pred) #round off the value to nearest integer 0 or 1\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87        32\n",
      "           1       0.77      0.85      0.81        20\n",
      "\n",
      "    accuracy                           0.85        52\n",
      "   macro avg       0.84      0.85      0.84        52\n",
      "weighted avg       0.85      0.85      0.85        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8551e0ab9876ec51073e0fff13c60ee316e8ca1cb46c814b591d91a5f899d8c5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
