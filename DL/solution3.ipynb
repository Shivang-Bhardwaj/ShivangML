{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train),(X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],28,28,1)\n",
    "X_test = X_test.reshape(X_test.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 58s 30ms/step - loss: 0.6998 - sparse_categorical_accuracy: 0.7467 - val_loss: 0.4775 - val_sparse_categorical_accuracy: 0.8284\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 52s 28ms/step - loss: 0.4726 - sparse_categorical_accuracy: 0.8297 - val_loss: 0.4019 - val_sparse_categorical_accuracy: 0.8533\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 50s 26ms/step - loss: 0.4042 - sparse_categorical_accuracy: 0.8538 - val_loss: 0.3559 - val_sparse_categorical_accuracy: 0.8697\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 47s 25ms/step - loss: 0.3661 - sparse_categorical_accuracy: 0.8666 - val_loss: 0.3530 - val_sparse_categorical_accuracy: 0.8716\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 48s 26ms/step - loss: 0.3403 - sparse_categorical_accuracy: 0.8783 - val_loss: 0.3683 - val_sparse_categorical_accuracy: 0.8690\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 49s 26ms/step - loss: 0.3204 - sparse_categorical_accuracy: 0.8823 - val_loss: 0.3286 - val_sparse_categorical_accuracy: 0.8810\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 56s 30ms/step - loss: 0.3061 - sparse_categorical_accuracy: 0.8885 - val_loss: 0.3211 - val_sparse_categorical_accuracy: 0.8822\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 48s 25ms/step - loss: 0.2950 - sparse_categorical_accuracy: 0.8918 - val_loss: 0.3148 - val_sparse_categorical_accuracy: 0.8851\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 47s 25ms/step - loss: 0.2817 - sparse_categorical_accuracy: 0.8981 - val_loss: 0.3092 - val_sparse_categorical_accuracy: 0.8881\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 48s 26ms/step - loss: 0.2716 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.3156 - val_sparse_categorical_accuracy: 0.8865\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 52s 28ms/step - loss: 0.2632 - sparse_categorical_accuracy: 0.9031 - val_loss: 0.3041 - val_sparse_categorical_accuracy: 0.8890\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 49s 26ms/step - loss: 0.2554 - sparse_categorical_accuracy: 0.9052 - val_loss: 0.3096 - val_sparse_categorical_accuracy: 0.8902\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 48s 26ms/step - loss: 0.2465 - sparse_categorical_accuracy: 0.9086 - val_loss: 0.3076 - val_sparse_categorical_accuracy: 0.8930\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 50s 27ms/step - loss: 0.2439 - sparse_categorical_accuracy: 0.9098 - val_loss: 0.3066 - val_sparse_categorical_accuracy: 0.8912\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 54s 29ms/step - loss: 0.2355 - sparse_categorical_accuracy: 0.9133 - val_loss: 0.2958 - val_sparse_categorical_accuracy: 0.8958\n"
     ]
    }
   ],
   "source": [
    "# using relu\n",
    "\n",
    "model = keras.Sequential([\n",
    "    \n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\",input_shape=(28,28,1)),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Conv2D(50, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Conv2D(100, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),      \n",
    "\n",
    "        layers.Flatten(),\n",
    "\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Dense(64, activation = 'relu'),\n",
    "\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Dense(10, activation=\"softmax\"),\n",
    "    ])\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "history = model.fit(X_train, y_train, validation_data=( X_test, y_test ), epochs=15, verbose=1)\n",
    "loss_train1 = history.history['loss']  # training loss\n",
    "loss_val1 = history.history['val_loss']  # validation loss\n",
    "acc_train1 = history.history['sparse_categorical_accuracy']   # training accuracy\n",
    "acc_val1 = history.history['val_sparse_categorical_accuracy']  # validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85      1000\n",
      "           1       0.99      0.97      0.98      1000\n",
      "           2       0.82      0.87      0.84      1000\n",
      "           3       0.89      0.90      0.90      1000\n",
      "           4       0.84      0.80      0.82      1000\n",
      "           5       0.98      0.97      0.97      1000\n",
      "           6       0.72      0.67      0.69      1000\n",
      "           7       0.94      0.97      0.96      1000\n",
      "           8       0.97      0.98      0.97      1000\n",
      "           9       0.97      0.96      0.96      1000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = [np.argmax(arr) for arr in model.predict(X_test)]\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 77s 40ms/step - loss: 0.6691 - accuracy: 0.7523\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 68s 36ms/step - loss: 0.4633 - accuracy: 0.8297\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 67s 36ms/step - loss: 0.4037 - accuracy: 0.8518\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 75s 40ms/step - loss: 0.3686 - accuracy: 0.8651\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 78s 42ms/step - loss: 0.3406 - accuracy: 0.8750\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 78s 42ms/step - loss: 0.3200 - accuracy: 0.8813\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 79s 42ms/step - loss: 0.3002 - accuracy: 0.8892\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 71s 38ms/step - loss: 0.2898 - accuracy: 0.8935\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 73s 39ms/step - loss: 0.2741 - accuracy: 0.8966\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 72s 39ms/step - loss: 0.2639 - accuracy: 0.9014\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 66s 35ms/step - loss: 0.2540 - accuracy: 0.9067\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 68s 36ms/step - loss: 0.2436 - accuracy: 0.9086\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 82s 44ms/step - loss: 0.2380 - accuracy: 0.9111\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 71s 38ms/step - loss: 0.2307 - accuracy: 0.9143\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 69s 37ms/step - loss: 0.2252 - accuracy: 0.9165\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3046 - accuracy: 0.8954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30463501811027527, 0.8953999876976013]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using swish\n",
    "\n",
    "model = keras.Sequential([\n",
    "    \n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"swish\",input_shape=(28,28,1)),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Conv2D(50, kernel_size=(3, 3), activation=\"swish\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Conv2D(100, kernel_size=(3, 3), activation=\"swish\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),      \n",
    "\n",
    "        layers.Flatten(),\n",
    "\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Dense(64, activation = 'swish'),\n",
    "\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Dense(10, activation=\"softmax\"),\n",
    "    ])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=15)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 51s 26ms/step - loss: 0.6509 - accuracy: 0.7661\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 71s 38ms/step - loss: 0.4624 - accuracy: 0.8323\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 64s 34ms/step - loss: 0.4092 - accuracy: 0.8529\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 65s 34ms/step - loss: 0.3766 - accuracy: 0.8663\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 65s 35ms/step - loss: 0.3521 - accuracy: 0.8731\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 65s 35ms/step - loss: 0.3345 - accuracy: 0.8806\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 64s 34ms/step - loss: 0.3212 - accuracy: 0.8840\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 63s 34ms/step - loss: 0.3067 - accuracy: 0.8899\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 60s 32ms/step - loss: 0.2972 - accuracy: 0.8931\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 63s 34ms/step - loss: 0.2861 - accuracy: 0.8970\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 64s 34ms/step - loss: 0.2752 - accuracy: 0.9019\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 64s 34ms/step - loss: 0.2695 - accuracy: 0.9025\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 63s 34ms/step - loss: 0.2613 - accuracy: 0.9058\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 63s 33ms/step - loss: 0.2557 - accuracy: 0.9079\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 64s 34ms/step - loss: 0.2493 - accuracy: 0.9096\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.3188 - accuracy: 0.8897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3187774121761322, 0.8896999955177307]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using softsign\n",
    "\n",
    "model = keras.Sequential([\n",
    "    \n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"softsign\",input_shape=(28,28,1)),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Conv2D(50, kernel_size=(3, 3), activation=\"softsign\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Conv2D(100, kernel_size=(3, 3), activation=\"softsign\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),      \n",
    "\n",
    "        layers.Flatten(),\n",
    "\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Dense(64, activation = 'softsign'),\n",
    "\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Dense(10, activation=\"softmax\"),\n",
    "    ])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=15)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 67s 35ms/step - loss: 0.9398 - accuracy: 0.6801\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 0.5841 - accuracy: 0.7923\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 89s 47ms/step - loss: 0.5042 - accuracy: 0.8224\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 90s 48ms/step - loss: 0.4566 - accuracy: 0.8369\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 90s 48ms/step - loss: 0.4174 - accuracy: 0.8506\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 91s 49ms/step - loss: 0.3969 - accuracy: 0.8565\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 82s 44ms/step - loss: 0.3754 - accuracy: 0.8651\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 90s 48ms/step - loss: 0.3566 - accuracy: 0.8723\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 92s 49ms/step - loss: 0.3437 - accuracy: 0.8748\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 76s 40ms/step - loss: 0.3310 - accuracy: 0.8794\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 91s 49ms/step - loss: 0.3199 - accuracy: 0.8838\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 91s 49ms/step - loss: 0.3103 - accuracy: 0.8867\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 90s 48ms/step - loss: 0.3010 - accuracy: 0.8889\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 89s 47ms/step - loss: 0.2922 - accuracy: 0.8921\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 91s 48ms/step - loss: 0.2854 - accuracy: 0.8939\n",
      "313/313 [==============================] - 6s 17ms/step - loss: 0.3545 - accuracy: 0.8813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35450804233551025, 0.8812999725341797]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using x.log(1+ |x|)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    \n",
    "        layers.Conv2D(32, kernel_size=(3, 3),input_shape=(28,28,1)),\n",
    "        layers.Lambda( lambda x :  x*tf.math.log(1+ tf.math.abs(x))  ),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Conv2D(50, kernel_size=(3, 3)),\n",
    "        layers.Lambda( lambda x :  x*tf.math.log(1+ tf.math.abs(x))  ),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Conv2D(100, kernel_size=(3, 3)),\n",
    "        layers.Lambda( lambda x :  x*tf.math.log(1+ tf.math.abs(x))  ),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),      \n",
    "\n",
    "        layers.Flatten(),\n",
    "\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Dense(64),\n",
    "        layers.Lambda( lambda x :  x*tf.math.log(1+ tf.math.abs(x))  ),\n",
    "\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Dense(10, activation=\"softmax\"),\n",
    "    ])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=15)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 68s 35ms/step - loss: 0.8641 - sparse_categorical_accuracy: 0.6924 - val_loss: 0.5676 - val_sparse_categorical_accuracy: 0.7989\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 67s 35ms/step - loss: 0.5669 - sparse_categorical_accuracy: 0.7975 - val_loss: 0.4745 - val_sparse_categorical_accuracy: 0.8298\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 66s 35ms/step - loss: 0.4950 - sparse_categorical_accuracy: 0.8223 - val_loss: 0.4645 - val_sparse_categorical_accuracy: 0.8270\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 69s 37ms/step - loss: 0.4576 - sparse_categorical_accuracy: 0.8357 - val_loss: 0.4080 - val_sparse_categorical_accuracy: 0.8547\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 68s 36ms/step - loss: 0.4248 - sparse_categorical_accuracy: 0.8468 - val_loss: 0.3892 - val_sparse_categorical_accuracy: 0.8560\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 66s 35ms/step - loss: 0.4071 - sparse_categorical_accuracy: 0.8526 - val_loss: 0.3844 - val_sparse_categorical_accuracy: 0.8622\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 67s 36ms/step - loss: 0.3918 - sparse_categorical_accuracy: 0.8583 - val_loss: 0.3757 - val_sparse_categorical_accuracy: 0.8626\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 66s 35ms/step - loss: 0.3763 - sparse_categorical_accuracy: 0.8637 - val_loss: 0.3889 - val_sparse_categorical_accuracy: 0.8534\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 67s 36ms/step - loss: 0.3669 - sparse_categorical_accuracy: 0.8676 - val_loss: 0.3831 - val_sparse_categorical_accuracy: 0.8630\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 71s 38ms/step - loss: 0.3550 - sparse_categorical_accuracy: 0.8697 - val_loss: 0.3590 - val_sparse_categorical_accuracy: 0.8676\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 69s 37ms/step - loss: 0.3460 - sparse_categorical_accuracy: 0.8749 - val_loss: 0.3458 - val_sparse_categorical_accuracy: 0.8757\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 68s 36ms/step - loss: 0.3382 - sparse_categorical_accuracy: 0.8769 - val_loss: 0.3514 - val_sparse_categorical_accuracy: 0.8735\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 68s 37ms/step - loss: 0.3336 - sparse_categorical_accuracy: 0.8789 - val_loss: 0.3542 - val_sparse_categorical_accuracy: 0.8711\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 70s 37ms/step - loss: 0.3269 - sparse_categorical_accuracy: 0.8810 - val_loss: 0.3455 - val_sparse_categorical_accuracy: 0.8746\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 69s 37ms/step - loss: 0.3239 - sparse_categorical_accuracy: 0.8827 - val_loss: 0.3493 - val_sparse_categorical_accuracy: 0.8691\n"
     ]
    }
   ],
   "source": [
    "# using custom function\n",
    "\n",
    "model = keras.Sequential([\n",
    "    \n",
    "        layers.Conv2D(32, kernel_size=(3, 3),input_shape=(28,28,1)),\n",
    "        layers.Lambda( lambda x : x* tf.sin(x) ),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Conv2D(50, kernel_size=(3, 3)),\n",
    "        layers.Lambda( lambda x :  x* tf.sin(x) ),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Conv2D(100, kernel_size=(3, 3)),\n",
    "        layers.Lambda( lambda x : x* tf.sin(x) ),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),      \n",
    "\n",
    "        layers.Flatten(),\n",
    "\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Dense(64),\n",
    "        layers.Lambda( lambda x : x* tf.sin(x) ),\n",
    "\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Dense(10, activation=\"softmax\"),\n",
    "    ])\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "history = model.fit(X_train, y_train, validation_data=( X_test, y_test ), epochs=15, verbose=1)\n",
    "loss_train2 = history.history['loss']  # training loss\n",
    "loss_val2 = history.history['val_loss']  # validation loss\n",
    "acc_train2 = history.history['sparse_categorical_accuracy']   # training accuracy\n",
    "acc_val2 = history.history['val_sparse_categorical_accuracy']  # validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 13ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83      1000\n",
      "           1       0.98      0.97      0.98      1000\n",
      "           2       0.78      0.82      0.80      1000\n",
      "           3       0.87      0.90      0.88      1000\n",
      "           4       0.86      0.63      0.72      1000\n",
      "           5       0.97      0.96      0.97      1000\n",
      "           6       0.60      0.67      0.64      1000\n",
      "           7       0.96      0.93      0.94      1000\n",
      "           8       0.98      0.97      0.98      1000\n",
      "           9       0.93      0.97      0.95      1000\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = [np.argmax(arr) for arr in model.predict(X_test)] \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 18ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1000\n",
      "           1       0.99      0.97      0.98      1000\n",
      "           2       0.81      0.78      0.80      1000\n",
      "           3       0.88      0.88      0.88      1000\n",
      "           4       0.78      0.83      0.81      1000\n",
      "           5       0.98      0.94      0.96      1000\n",
      "           6       0.65      0.68      0.67      1000\n",
      "           7       0.94      0.95      0.95      1000\n",
      "           8       0.99      0.96      0.97      1000\n",
      "           9       0.94      0.97      0.95      1000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = [np.argmax(arr) for arr in model.predict(X_test)]    # log(|x| + 1)*sin(x)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 12ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.73      0.80      1000\n",
      "           1       0.99      0.97      0.98      1000\n",
      "           2       0.79      0.83      0.81      1000\n",
      "           3       0.84      0.92      0.88      1000\n",
      "           4       0.79      0.83      0.81      1000\n",
      "           5       0.97      0.96      0.96      1000\n",
      "           6       0.64      0.65      0.65      1000\n",
      "           7       0.96      0.94      0.95      1000\n",
      "           8       0.99      0.96      0.97      1000\n",
      "           9       0.94      0.97      0.96      1000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = [np.argmax(arr) for arr in model.predict(X_test)]   # ( x - x/|x|+1 )\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d222c0ea30c03d9b1e6630c1c313bfaf3a7c4d9233845a6eafe7bbde919cfdc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
