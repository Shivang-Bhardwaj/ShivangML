{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import  pandas as pd\r\n",
    "import numpy as np\r\n",
    "from tensorflow import keras\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df=pd.read_csv(r'C:\\Users\\DELL PC\\Desktop\\ML\\DL\\useful_data\\insurance.csv')\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Age  Previously_Insured  Response\n",
       "0   44                   0         1\n",
       "1   76                   0         0\n",
       "2   47                   0         1\n",
       "3   21                   1         0\n",
       "4   29                   1         0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import tensorflow as tf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train,X_test,y_train,y_test=train_test_split(df[['Age','Previously_Insured']],df.Response,test_size=.3,random_state=58)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "X_train_scaled=X_train.copy()                   #Scaling\r\n",
    "X_train_scaled['Age']=X_train_scaled['Age']/100\r\n",
    "\r\n",
    "X_test_scaled=X_test.copy()\r\n",
    "X_test_scaled['Age']=X_test_scaled['Age']/100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model=keras.Sequential([\r\n",
    "    keras.layers.Dense(1,input_shape=(2,),activation='sigmoid',kernel_initializer='ones',bias_initializer='zeros')\r\n",
    "])\r\n",
    "model.compile(\r\n",
    "    optimizer='adam',\r\n",
    "    loss='binary_crossentropy',\r\n",
    "    metrics=['accuracy']\r\n",
    ")\r\n",
    "model.fit(X_train_scaled,y_train,epochs=500)\r\n",
    "\r\n",
    "\r\n",
    "#kernel_initilizer --> initial weights for all inputs\r\n",
    "#bias_initializer --> initial bias(or intercept)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/500\n",
      "27/27 [==============================] - 3s 4ms/step - loss: 1.1539 - accuracy: 0.1274\n",
      "Epoch 2/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 1.1244 - accuracy: 0.1274\n",
      "Epoch 3/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1.0956 - accuracy: 0.1274\n",
      "Epoch 4/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 1.0677 - accuracy: 0.1274\n",
      "Epoch 5/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 1.0406 - accuracy: 0.1274\n",
      "Epoch 6/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 1.0138 - accuracy: 0.1274\n",
      "Epoch 7/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9878 - accuracy: 0.1321\n",
      "Epoch 8/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9628 - accuracy: 0.1893\n",
      "Epoch 9/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9384 - accuracy: 0.2202\n",
      "Epoch 10/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.9147 - accuracy: 0.2310\n",
      "Epoch 11/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8918 - accuracy: 0.2452\n",
      "Epoch 12/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8695 - accuracy: 0.2738\n",
      "Epoch 13/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8481 - accuracy: 0.3095\n",
      "Epoch 14/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8275 - accuracy: 0.3381\n",
      "Epoch 15/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8074 - accuracy: 0.3631\n",
      "Epoch 16/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.7879 - accuracy: 0.3774\n",
      "Epoch 17/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.7694 - accuracy: 0.4024\n",
      "Epoch 18/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.7515 - accuracy: 0.4143\n",
      "Epoch 19/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.7343 - accuracy: 0.4214\n",
      "Epoch 20/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.7178 - accuracy: 0.4214\n",
      "Epoch 21/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.7017 - accuracy: 0.4214\n",
      "Epoch 22/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.4214\n",
      "Epoch 23/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.4226\n",
      "Epoch 24/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6573 - accuracy: 0.6095\n",
      "Epoch 25/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6436 - accuracy: 0.7393\n",
      "Epoch 26/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6306 - accuracy: 0.7810\n",
      "Epoch 27/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.8286\n",
      "Epoch 28/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6060 - accuracy: 0.8619\n",
      "Epoch 29/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5945 - accuracy: 0.8726\n",
      "Epoch 30/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.8726\n",
      "Epoch 31/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.8726\n",
      "Epoch 32/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.8726\n",
      "Epoch 33/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.8726\n",
      "Epoch 34/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.8726\n",
      "Epoch 35/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.8726\n",
      "Epoch 36/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.8726\n",
      "Epoch 37/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.8726\n",
      "Epoch 38/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.8726\n",
      "Epoch 39/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.8726\n",
      "Epoch 40/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.8726\n",
      "Epoch 41/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.8726\n",
      "Epoch 42/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.8726\n",
      "Epoch 43/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.8726\n",
      "Epoch 44/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.8726\n",
      "Epoch 45/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.8726\n",
      "Epoch 46/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8726\n",
      "Epoch 47/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.8726\n",
      "Epoch 48/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.8726\n",
      "Epoch 49/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8726\n",
      "Epoch 50/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.8726\n",
      "Epoch 51/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8726\n",
      "Epoch 52/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8726\n",
      "Epoch 53/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8726\n",
      "Epoch 54/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8726\n",
      "Epoch 55/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8726\n",
      "Epoch 56/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.8726\n",
      "Epoch 57/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8726\n",
      "Epoch 58/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8726\n",
      "Epoch 59/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8726\n",
      "Epoch 60/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8726\n",
      "Epoch 61/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8726\n",
      "Epoch 62/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8726\n",
      "Epoch 63/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8726\n",
      "Epoch 64/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8726\n",
      "Epoch 65/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3951 - accuracy: 0.8726\n",
      "Epoch 66/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8726\n",
      "Epoch 67/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3908 - accuracy: 0.8726\n",
      "Epoch 68/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8726\n",
      "Epoch 69/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8726\n",
      "Epoch 70/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8726\n",
      "Epoch 71/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8726\n",
      "Epoch 72/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3817 - accuracy: 0.8726\n",
      "Epoch 73/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8726\n",
      "Epoch 74/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8726\n",
      "Epoch 75/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8726\n",
      "Epoch 76/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8726\n",
      "Epoch 77/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8726\n",
      "Epoch 78/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8726\n",
      "Epoch 79/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8726\n",
      "Epoch 80/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8726\n",
      "Epoch 81/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3693 - accuracy: 0.8726\n",
      "Epoch 82/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8726\n",
      "Epoch 83/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8726\n",
      "Epoch 84/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8726\n",
      "Epoch 85/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8726\n",
      "Epoch 86/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8726\n",
      "Epoch 87/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3631 - accuracy: 0.8726\n",
      "Epoch 88/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8726\n",
      "Epoch 89/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8726\n",
      "Epoch 90/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8726\n",
      "Epoch 91/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8726\n",
      "Epoch 92/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8726\n",
      "Epoch 93/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8726\n",
      "Epoch 94/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3571 - accuracy: 0.8726\n",
      "Epoch 95/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8726\n",
      "Epoch 96/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8726\n",
      "Epoch 97/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8726\n",
      "Epoch 98/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8726\n",
      "Epoch 99/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8726\n",
      "Epoch 100/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8726\n",
      "Epoch 101/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8726\n",
      "Epoch 102/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8726\n",
      "Epoch 103/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8726\n",
      "Epoch 104/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3506 - accuracy: 0.8726\n",
      "Epoch 105/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.8726\n",
      "Epoch 106/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8726\n",
      "Epoch 107/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.8726\n",
      "Epoch 108/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8726\n",
      "Epoch 109/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8726\n",
      "Epoch 110/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8726\n",
      "Epoch 111/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3469 - accuracy: 0.8726\n",
      "Epoch 112/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3464 - accuracy: 0.8726\n",
      "Epoch 113/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3459 - accuracy: 0.8726\n",
      "Epoch 114/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3454 - accuracy: 0.8726\n",
      "Epoch 115/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8726\n",
      "Epoch 116/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8726\n",
      "Epoch 117/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8726\n",
      "Epoch 118/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8726\n",
      "Epoch 119/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8726\n",
      "Epoch 120/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3428 - accuracy: 0.8726\n",
      "Epoch 121/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8726\n",
      "Epoch 122/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8726\n",
      "Epoch 123/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.8726\n",
      "Epoch 124/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8726\n",
      "Epoch 125/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8726\n",
      "Epoch 126/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 0.8726\n",
      "Epoch 127/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8726\n",
      "Epoch 128/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8726\n",
      "Epoch 129/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.8726\n",
      "Epoch 130/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3387 - accuracy: 0.8726\n",
      "Epoch 131/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8726\n",
      "Epoch 132/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8726\n",
      "Epoch 133/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8726\n",
      "Epoch 134/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8726\n",
      "Epoch 135/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8726\n",
      "Epoch 136/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8726\n",
      "Epoch 137/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8726\n",
      "Epoch 138/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8726\n",
      "Epoch 139/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8726\n",
      "Epoch 140/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8726\n",
      "Epoch 141/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3347 - accuracy: 0.8726\n",
      "Epoch 142/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8726\n",
      "Epoch 143/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8726\n",
      "Epoch 144/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8726\n",
      "Epoch 145/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8726\n",
      "Epoch 146/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8726\n",
      "Epoch 147/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8726\n",
      "Epoch 148/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8726\n",
      "Epoch 149/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8726\n",
      "Epoch 150/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8726\n",
      "Epoch 151/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8726\n",
      "Epoch 152/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8726\n",
      "Epoch 153/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8726\n",
      "Epoch 154/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3303 - accuracy: 0.8726\n",
      "Epoch 155/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8726\n",
      "Epoch 156/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8726\n",
      "Epoch 157/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8726\n",
      "Epoch 158/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8726\n",
      "Epoch 159/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8726\n",
      "Epoch 160/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8726\n",
      "Epoch 161/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8726\n",
      "Epoch 162/500\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3277 - accuracy: 0.8726\n",
      "Epoch 163/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8726\n",
      "Epoch 164/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8726\n",
      "Epoch 165/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8726\n",
      "Epoch 166/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8726\n",
      "Epoch 167/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8726\n",
      "Epoch 168/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8726\n",
      "Epoch 169/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.8726\n",
      "Epoch 170/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8726\n",
      "Epoch 171/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3249 - accuracy: 0.8726\n",
      "Epoch 172/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8726\n",
      "Epoch 173/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8726\n",
      "Epoch 174/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8726\n",
      "Epoch 175/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3238 - accuracy: 0.8726\n",
      "Epoch 176/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8726\n",
      "Epoch 177/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8726\n",
      "Epoch 178/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8726\n",
      "Epoch 179/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8726\n",
      "Epoch 180/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3224 - accuracy: 0.8726\n",
      "Epoch 181/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8726\n",
      "Epoch 182/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8726\n",
      "Epoch 183/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.8726\n",
      "Epoch 184/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.8726\n",
      "Epoch 185/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8726\n",
      "Epoch 186/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8726\n",
      "Epoch 187/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8726\n",
      "Epoch 188/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8726\n",
      "Epoch 189/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8726\n",
      "Epoch 190/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8726\n",
      "Epoch 191/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8726\n",
      "Epoch 192/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3193 - accuracy: 0.8726\n",
      "Epoch 193/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8726\n",
      "Epoch 194/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8726\n",
      "Epoch 195/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.8726\n",
      "Epoch 196/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8726\n",
      "Epoch 197/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8726\n",
      "Epoch 198/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8726\n",
      "Epoch 199/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8726\n",
      "Epoch 200/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8726\n",
      "Epoch 201/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3172 - accuracy: 0.8726\n",
      "Epoch 202/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8726\n",
      "Epoch 203/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8726\n",
      "Epoch 204/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8726\n",
      "Epoch 205/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8726\n",
      "Epoch 206/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.8726\n",
      "Epoch 207/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8726\n",
      "Epoch 208/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8726\n",
      "Epoch 209/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8726\n",
      "Epoch 210/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8726\n",
      "Epoch 211/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8726\n",
      "Epoch 212/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8726\n",
      "Epoch 213/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8726\n",
      "Epoch 214/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.8726\n",
      "Epoch 215/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8726\n",
      "Epoch 216/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8726\n",
      "Epoch 217/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.8726\n",
      "Epoch 218/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8726\n",
      "Epoch 219/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8726\n",
      "Epoch 220/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3132 - accuracy: 0.8726\n",
      "Epoch 221/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3131 - accuracy: 0.8726\n",
      "Epoch 222/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8726\n",
      "Epoch 223/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8726\n",
      "Epoch 224/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8726\n",
      "Epoch 225/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8726\n",
      "Epoch 226/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8726\n",
      "Epoch 227/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8726\n",
      "Epoch 228/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8726\n",
      "Epoch 229/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8726\n",
      "Epoch 230/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8726\n",
      "Epoch 231/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8726\n",
      "Epoch 232/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8726\n",
      "Epoch 233/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8726\n",
      "Epoch 234/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8726\n",
      "Epoch 235/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8726\n",
      "Epoch 236/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8726\n",
      "Epoch 237/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8726\n",
      "Epoch 238/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8726\n",
      "Epoch 239/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8726\n",
      "Epoch 240/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8726\n",
      "Epoch 241/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8726\n",
      "Epoch 242/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8726\n",
      "Epoch 243/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.3095 - accuracy: 0.8726\n",
      "Epoch 244/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8726\n",
      "Epoch 245/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8726\n",
      "Epoch 246/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8726\n",
      "Epoch 247/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8726\n",
      "Epoch 248/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8726\n",
      "Epoch 249/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3086 - accuracy: 0.8726\n",
      "Epoch 250/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8726\n",
      "Epoch 251/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8726\n",
      "Epoch 252/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8726\n",
      "Epoch 253/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8726\n",
      "Epoch 254/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3079 - accuracy: 0.8726\n",
      "Epoch 255/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8726\n",
      "Epoch 256/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8726\n",
      "Epoch 257/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8726\n",
      "Epoch 258/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8726\n",
      "Epoch 259/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3073 - accuracy: 0.8726\n",
      "Epoch 260/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8726\n",
      "Epoch 261/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8726\n",
      "Epoch 262/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8726\n",
      "Epoch 263/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3069 - accuracy: 0.8726\n",
      "Epoch 264/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8726\n",
      "Epoch 265/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3066 - accuracy: 0.8726\n",
      "Epoch 266/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8726\n",
      "Epoch 267/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8726\n",
      "Epoch 268/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3062 - accuracy: 0.8726\n",
      "Epoch 269/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3061 - accuracy: 0.8726\n",
      "Epoch 270/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.8726\n",
      "Epoch 271/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8726\n",
      "Epoch 272/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8726\n",
      "Epoch 273/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3058 - accuracy: 0.8726\n",
      "Epoch 274/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8726\n",
      "Epoch 275/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8726\n",
      "Epoch 276/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8726\n",
      "Epoch 277/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8726\n",
      "Epoch 278/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8726\n",
      "Epoch 279/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8726\n",
      "Epoch 280/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3050 - accuracy: 0.8726\n",
      "Epoch 281/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.8726\n",
      "Epoch 282/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.8726\n",
      "Epoch 283/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3047 - accuracy: 0.8726\n",
      "Epoch 284/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3047 - accuracy: 0.8726\n",
      "Epoch 285/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8726\n",
      "Epoch 286/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3045 - accuracy: 0.8726\n",
      "Epoch 287/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8726\n",
      "Epoch 288/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8726\n",
      "Epoch 289/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3042 - accuracy: 0.8726\n",
      "Epoch 290/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.8726\n",
      "Epoch 291/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.8726\n",
      "Epoch 292/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8726\n",
      "Epoch 293/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.8726\n",
      "Epoch 294/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3038 - accuracy: 0.8726\n",
      "Epoch 295/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8726\n",
      "Epoch 296/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8726\n",
      "Epoch 297/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8726\n",
      "Epoch 298/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3035 - accuracy: 0.8726\n",
      "Epoch 299/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8726\n",
      "Epoch 300/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8726\n",
      "Epoch 301/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8726\n",
      "Epoch 302/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8726\n",
      "Epoch 303/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8726\n",
      "Epoch 304/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8726\n",
      "Epoch 305/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3030 - accuracy: 0.8726\n",
      "Epoch 306/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.8726\n",
      "Epoch 307/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8726\n",
      "Epoch 308/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8726\n",
      "Epoch 309/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8726\n",
      "Epoch 310/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.8726\n",
      "Epoch 311/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.8726\n",
      "Epoch 312/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3025 - accuracy: 0.8726\n",
      "Epoch 313/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8726\n",
      "Epoch 314/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8726\n",
      "Epoch 315/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8726\n",
      "Epoch 316/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8726\n",
      "Epoch 317/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3022 - accuracy: 0.8726\n",
      "Epoch 318/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.8726\n",
      "Epoch 319/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.8726\n",
      "Epoch 320/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3020 - accuracy: 0.8726\n",
      "Epoch 321/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3020 - accuracy: 0.8726\n",
      "Epoch 322/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3019 - accuracy: 0.8726\n",
      "Epoch 323/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3018 - accuracy: 0.8726\n",
      "Epoch 324/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3018 - accuracy: 0.8726\n",
      "Epoch 325/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3017 - accuracy: 0.8726\n",
      "Epoch 326/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3017 - accuracy: 0.8726\n",
      "Epoch 327/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.8726\n",
      "Epoch 328/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.8726\n",
      "Epoch 329/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3015 - accuracy: 0.8726\n",
      "Epoch 330/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3015 - accuracy: 0.8726\n",
      "Epoch 331/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8726\n",
      "Epoch 332/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8726\n",
      "Epoch 333/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8726\n",
      "Epoch 334/500\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3013 - accuracy: 0.8726\n",
      "Epoch 335/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3012 - accuracy: 0.8726\n",
      "Epoch 336/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3012 - accuracy: 0.8726\n",
      "Epoch 337/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3011 - accuracy: 0.8726\n",
      "Epoch 338/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3011 - accuracy: 0.8726\n",
      "Epoch 339/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3010 - accuracy: 0.8726\n",
      "Epoch 340/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.8726\n",
      "Epoch 341/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.8726\n",
      "Epoch 342/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.8726\n",
      "Epoch 343/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3008 - accuracy: 0.8726\n",
      "Epoch 344/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3008 - accuracy: 0.8726\n",
      "Epoch 345/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3008 - accuracy: 0.8726\n",
      "Epoch 346/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3007 - accuracy: 0.8726\n",
      "Epoch 347/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3007 - accuracy: 0.8726\n",
      "Epoch 348/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3006 - accuracy: 0.8726\n",
      "Epoch 349/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.3006 - accuracy: 0.8726\n",
      "Epoch 350/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3005 - accuracy: 0.8726\n",
      "Epoch 351/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3005 - accuracy: 0.8726\n",
      "Epoch 352/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8726\n",
      "Epoch 353/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8726\n",
      "Epoch 354/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8726\n",
      "Epoch 355/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8726\n",
      "Epoch 356/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3003 - accuracy: 0.8726\n",
      "Epoch 357/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8726\n",
      "Epoch 358/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3002 - accuracy: 0.8726\n",
      "Epoch 359/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3002 - accuracy: 0.8726\n",
      "Epoch 360/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.8726\n",
      "Epoch 361/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3001 - accuracy: 0.8726\n",
      "Epoch 362/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.8726\n",
      "Epoch 363/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3001 - accuracy: 0.8726\n",
      "Epoch 364/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3000 - accuracy: 0.8726\n",
      "Epoch 365/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3000 - accuracy: 0.8726\n",
      "Epoch 366/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.8726\n",
      "Epoch 367/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3000 - accuracy: 0.8726\n",
      "Epoch 368/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3000 - accuracy: 0.8726\n",
      "Epoch 369/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.8726\n",
      "Epoch 370/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2998 - accuracy: 0.8726\n",
      "Epoch 371/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2998 - accuracy: 0.8726\n",
      "Epoch 372/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.8726\n",
      "Epoch 373/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.8726\n",
      "Epoch 374/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.8726\n",
      "Epoch 375/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.8726\n",
      "Epoch 376/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.8726\n",
      "Epoch 377/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.8726\n",
      "Epoch 378/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.8726\n",
      "Epoch 379/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.8726\n",
      "Epoch 380/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2995 - accuracy: 0.8726\n",
      "Epoch 381/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2995 - accuracy: 0.8726\n",
      "Epoch 382/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.8726\n",
      "Epoch 383/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.8726\n",
      "Epoch 384/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.8726\n",
      "Epoch 385/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.8726\n",
      "Epoch 386/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.8726\n",
      "Epoch 387/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.8726\n",
      "Epoch 388/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.8726\n",
      "Epoch 389/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2992 - accuracy: 0.8726\n",
      "Epoch 390/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2992 - accuracy: 0.8726\n",
      "Epoch 391/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2992 - accuracy: 0.8726\n",
      "Epoch 392/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2992 - accuracy: 0.8726\n",
      "Epoch 393/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2992 - accuracy: 0.8726\n",
      "Epoch 394/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.8726\n",
      "Epoch 395/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2991 - accuracy: 0.8726\n",
      "Epoch 396/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2990 - accuracy: 0.8726\n",
      "Epoch 397/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.8726\n",
      "Epoch 398/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2990 - accuracy: 0.8726\n",
      "Epoch 399/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2990 - accuracy: 0.8726\n",
      "Epoch 400/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2990 - accuracy: 0.8726\n",
      "Epoch 401/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2990 - accuracy: 0.8726\n",
      "Epoch 402/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2990 - accuracy: 0.8726\n",
      "Epoch 403/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.8726\n",
      "Epoch 404/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.8726\n",
      "Epoch 405/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.8726\n",
      "Epoch 406/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.8726\n",
      "Epoch 407/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2988 - accuracy: 0.8726\n",
      "Epoch 408/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2988 - accuracy: 0.8726\n",
      "Epoch 409/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.8726\n",
      "Epoch 410/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2988 - accuracy: 0.8726\n",
      "Epoch 411/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2987 - accuracy: 0.8726\n",
      "Epoch 412/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2987 - accuracy: 0.8726\n",
      "Epoch 413/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2987 - accuracy: 0.8726\n",
      "Epoch 414/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2987 - accuracy: 0.8726\n",
      "Epoch 415/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2987 - accuracy: 0.8726\n",
      "Epoch 416/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2987 - accuracy: 0.8726\n",
      "Epoch 417/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8726\n",
      "Epoch 418/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2987 - accuracy: 0.8726\n",
      "Epoch 419/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8726\n",
      "Epoch 420/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2986 - accuracy: 0.8726\n",
      "Epoch 421/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8726\n",
      "Epoch 422/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8726\n",
      "Epoch 423/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 0.8726\n",
      "Epoch 424/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 0.8726\n",
      "Epoch 425/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 0.8726\n",
      "Epoch 426/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 0.8726\n",
      "Epoch 427/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 0.8726\n",
      "Epoch 428/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 0.8726\n",
      "Epoch 429/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8726\n",
      "Epoch 430/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2984 - accuracy: 0.8726\n",
      "Epoch 431/500\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2984 - accuracy: 0.8726\n",
      "Epoch 432/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8726\n",
      "Epoch 433/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8726\n",
      "Epoch 434/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.8726\n",
      "Epoch 435/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.8726\n",
      "Epoch 436/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.8726\n",
      "Epoch 437/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2983 - accuracy: 0.8726\n",
      "Epoch 438/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.8726\n",
      "Epoch 439/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.8726\n",
      "Epoch 440/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.8726\n",
      "Epoch 441/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8726\n",
      "Epoch 442/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8726\n",
      "Epoch 443/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8726\n",
      "Epoch 444/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8726\n",
      "Epoch 445/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8726\n",
      "Epoch 446/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8726\n",
      "Epoch 447/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2982 - accuracy: 0.8726\n",
      "Epoch 448/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8726\n",
      "Epoch 449/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8726\n",
      "Epoch 450/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.8726\n",
      "Epoch 451/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8726\n",
      "Epoch 452/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8726\n",
      "Epoch 453/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8726\n",
      "Epoch 454/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8726\n",
      "Epoch 455/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8726\n",
      "Epoch 456/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8726\n",
      "Epoch 457/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8726\n",
      "Epoch 458/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2980 - accuracy: 0.8726\n",
      "Epoch 459/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2980 - accuracy: 0.8726\n",
      "Epoch 460/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2980 - accuracy: 0.8726\n",
      "Epoch 461/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8726\n",
      "Epoch 462/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2980 - accuracy: 0.8726\n",
      "Epoch 463/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2980 - accuracy: 0.8726\n",
      "Epoch 464/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2980 - accuracy: 0.8726\n",
      "Epoch 465/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2980 - accuracy: 0.8726\n",
      "Epoch 466/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2979 - accuracy: 0.8726\n",
      "Epoch 467/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2979 - accuracy: 0.8726\n",
      "Epoch 468/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2979 - accuracy: 0.8726\n",
      "Epoch 469/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2979 - accuracy: 0.8726\n",
      "Epoch 470/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2979 - accuracy: 0.8726\n",
      "Epoch 471/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2979 - accuracy: 0.8726\n",
      "Epoch 472/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2979 - accuracy: 0.8726\n",
      "Epoch 473/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2979 - accuracy: 0.8726\n",
      "Epoch 474/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2978 - accuracy: 0.8726\n",
      "Epoch 475/500\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2978 - accuracy: 0.8726\n",
      "Epoch 476/500\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2978 - accuracy: 0.8726\n",
      "Epoch 477/500\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2978 - accuracy: 0.8726\n",
      "Epoch 478/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2978 - accuracy: 0.8726\n",
      "Epoch 479/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2978 - accuracy: 0.8726\n",
      "Epoch 480/500\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2978 - accuracy: 0.8726\n",
      "Epoch 481/500\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2978 - accuracy: 0.8726\n",
      "Epoch 482/500\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2978 - accuracy: 0.8726\n",
      "Epoch 483/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2978 - accuracy: 0.8726\n",
      "Epoch 484/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2978 - accuracy: 0.8726\n",
      "Epoch 485/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2977 - accuracy: 0.8726\n",
      "Epoch 486/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2978 - accuracy: 0.8726\n",
      "Epoch 487/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2977 - accuracy: 0.8726\n",
      "Epoch 488/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8726\n",
      "Epoch 489/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8726\n",
      "Epoch 490/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8726\n",
      "Epoch 491/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2977 - accuracy: 0.8726\n",
      "Epoch 492/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2977 - accuracy: 0.8726\n",
      "Epoch 493/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8726\n",
      "Epoch 494/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2977 - accuracy: 0.8726\n",
      "Epoch 495/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2977 - accuracy: 0.8726\n",
      "Epoch 496/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8726\n",
      "Epoch 497/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8726\n",
      "Epoch 498/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8726\n",
      "Epoch 499/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2976 - accuracy: 0.8726\n",
      "Epoch 500/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2976 - accuracy: 0.8726\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ef7752ac40>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "model.evaluate(X_test_scaled,y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.8837\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.2896100580692291, 0.8836565017700195]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "model.predict(X_test_scaled)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.24693412],\n",
       "       [0.22561523],\n",
       "       [0.00132242],\n",
       "       [0.00132242],\n",
       "       [0.22896364],\n",
       "       [0.22896364],\n",
       "       [0.00132242],\n",
       "       [0.00132748],\n",
       "       [0.21772131],\n",
       "       [0.00136337],\n",
       "       [0.00131238],\n",
       "       [0.00130248],\n",
       "       [0.24551868],\n",
       "       [0.00135821],\n",
       "       [0.00133258],\n",
       "       [0.00132748],\n",
       "       [0.23098943],\n",
       "       [0.23852399],\n",
       "       [0.24340582],\n",
       "       [0.22033024],\n",
       "       [0.00130746],\n",
       "       [0.2350784 ],\n",
       "       [0.00140554],\n",
       "       [0.2303128 ],\n",
       "       [0.23991194],\n",
       "       [0.00131238],\n",
       "       [0.00132748],\n",
       "       [0.23166743],\n",
       "       [0.00136852],\n",
       "       [0.22628212],\n",
       "       [0.21837142],\n",
       "       [0.00131741],\n",
       "       [0.23302767],\n",
       "       [0.22164315],\n",
       "       [0.2350784 ],\n",
       "       [0.2378321 ],\n",
       "       [0.21902299],\n",
       "       [0.00132748],\n",
       "       [0.21772131],\n",
       "       [0.22164315],\n",
       "       [0.00143254],\n",
       "       [0.00132242],\n",
       "       [0.24130535],\n",
       "       [0.2378321 ],\n",
       "       [0.00134271],\n",
       "       [0.00130746],\n",
       "       [0.23234683],\n",
       "       [0.00132748],\n",
       "       [0.24906754],\n",
       "       [0.22428563],\n",
       "       [0.21772131],\n",
       "       [0.00149953],\n",
       "       [0.2196759 ],\n",
       "       [0.2350784 ],\n",
       "       [0.24340582],\n",
       "       [0.00136337],\n",
       "       [0.22963753],\n",
       "       [0.00161815],\n",
       "       [0.21772131],\n",
       "       [0.21837142],\n",
       "       [0.23714164],\n",
       "       [0.00143254],\n",
       "       [0.22428563],\n",
       "       [0.24340582],\n",
       "       [0.2276201 ],\n",
       "       [0.23302767],\n",
       "       [0.00146008],\n",
       "       [0.22896364],\n",
       "       [0.00133762],\n",
       "       [0.2533711 ],\n",
       "       [0.00135821],\n",
       "       [0.00133762],\n",
       "       [0.21902299],\n",
       "       [0.00131238],\n",
       "       [0.00136337],\n",
       "       [0.00136852],\n",
       "       [0.21837142],\n",
       "       [0.2533711 ],\n",
       "       [0.24200416],\n",
       "       [0.22963753],\n",
       "       [0.0013479 ],\n",
       "       [0.00138432],\n",
       "       [0.00130746],\n",
       "       [0.24764389],\n",
       "       [0.22033024],\n",
       "       [0.23166743],\n",
       "       [0.23370987],\n",
       "       [0.21902299],\n",
       "       [0.00134271],\n",
       "       [0.2196759 ],\n",
       "       [0.23166743],\n",
       "       [0.23852399],\n",
       "       [0.24200416],\n",
       "       [0.00144348],\n",
       "       [0.00145453],\n",
       "       [0.00134271],\n",
       "       [0.00135297],\n",
       "       [0.21707252],\n",
       "       [0.00136852],\n",
       "       [0.00131238],\n",
       "       [0.2276201 ],\n",
       "       [0.22164315],\n",
       "       [0.00154001],\n",
       "       [0.23576477],\n",
       "       [0.23576477],\n",
       "       [0.0015637 ],\n",
       "       [0.00143254],\n",
       "       [0.00131741],\n",
       "       [0.23302767],\n",
       "       [0.2196759 ],\n",
       "       [0.00131741],\n",
       "       [0.24200416],\n",
       "       [0.22362292],\n",
       "       [0.23991194],\n",
       "       [0.00136337],\n",
       "       [0.00136852],\n",
       "       [0.23576477],\n",
       "       [0.24622574],\n",
       "       [0.23370987],\n",
       "       [0.00131741],\n",
       "       [0.22829118],\n",
       "       [0.24551868],\n",
       "       [0.21902299],\n",
       "       [0.00133258],\n",
       "       [0.24340582],\n",
       "       [0.00131238],\n",
       "       [0.2303128 ],\n",
       "       [0.00132748],\n",
       "       [0.23852399],\n",
       "       [0.24340582],\n",
       "       [0.00133762],\n",
       "       [0.23645252],\n",
       "       [0.22428563],\n",
       "       [0.2196759 ],\n",
       "       [0.2562673 ],\n",
       "       [0.22963753],\n",
       "       [0.2350784 ],\n",
       "       [0.2303128 ],\n",
       "       [0.00132242],\n",
       "       [0.22628212],\n",
       "       [0.00145453],\n",
       "       [0.00135821],\n",
       "       [0.21772131],\n",
       "       [0.24978137],\n",
       "       [0.21772131],\n",
       "       [0.2504966 ],\n",
       "       [0.00131238],\n",
       "       [0.21707252],\n",
       "       [0.22033024],\n",
       "       [0.23991194],\n",
       "       [0.24410877],\n",
       "       [0.00132748],\n",
       "       [0.2350784 ],\n",
       "       [0.00147122],\n",
       "       [0.00133258],\n",
       "       [0.23302767],\n",
       "       [0.00131238],\n",
       "       [0.2269504 ],\n",
       "       [0.00134271],\n",
       "       [0.00131741],\n",
       "       [0.24622574],\n",
       "       [0.23166743],\n",
       "       [0.22033024],\n",
       "       [0.00131741],\n",
       "       [0.22561523],\n",
       "       [0.21707252],\n",
       "       [0.23166743],\n",
       "       [0.00140017],\n",
       "       [0.00151098],\n",
       "       [0.00143254],\n",
       "       [0.21837142],\n",
       "       [0.2303128 ],\n",
       "       [0.00144905],\n",
       "       [0.2276201 ],\n",
       "       [0.00132242],\n",
       "       [0.2504966 ],\n",
       "       [0.22494972],\n",
       "       [0.00130746],\n",
       "       [0.22164315],\n",
       "       [0.2196759 ],\n",
       "       [0.21772131],\n",
       "       [0.00142169],\n",
       "       [0.23439342],\n",
       "       [0.00138432],\n",
       "       [0.00131238],\n",
       "       [0.00133762],\n",
       "       [0.21902299],\n",
       "       [0.00132242],\n",
       "       [0.00146008],\n",
       "       [0.24835503],\n",
       "       [0.00132242],\n",
       "       [0.00151676],\n",
       "       [0.23645252],\n",
       "       [0.00132748],\n",
       "       [0.00131741],\n",
       "       [0.24340582],\n",
       "       [0.00136337],\n",
       "       [0.24060795],\n",
       "       [0.22561523],\n",
       "       [0.00132242],\n",
       "       [0.22033024],\n",
       "       [0.2378321 ],\n",
       "       [0.21902299],\n",
       "       [0.22164315],\n",
       "       [0.21772131],\n",
       "       [0.00132242],\n",
       "       [0.00143254],\n",
       "       [0.00133762],\n",
       "       [0.22494972],\n",
       "       [0.00131741],\n",
       "       [0.00133762],\n",
       "       [0.23714164],\n",
       "       [0.2512132 ],\n",
       "       [0.00135821],\n",
       "       [0.00132242],\n",
       "       [0.22628212],\n",
       "       [0.2196759 ],\n",
       "       [0.2196759 ],\n",
       "       [0.23302767],\n",
       "       [0.22362292],\n",
       "       [0.24906754],\n",
       "       [0.00131238],\n",
       "       [0.23370987],\n",
       "       [0.00132748],\n",
       "       [0.22164315],\n",
       "       [0.22230166],\n",
       "       [0.00131238],\n",
       "       [0.2269504 ],\n",
       "       [0.2196759 ],\n",
       "       [0.22033024],\n",
       "       [0.23234683],\n",
       "       [0.2350784 ],\n",
       "       [0.23166743],\n",
       "       [0.25193113],\n",
       "       [0.00161815],\n",
       "       [0.23921728],\n",
       "       [0.23991194],\n",
       "       [0.00132242],\n",
       "       [0.00160587],\n",
       "       [0.00145453],\n",
       "       [0.23166743],\n",
       "       [0.22494972],\n",
       "       [0.00133258],\n",
       "       [0.00154594],\n",
       "       [0.00134271],\n",
       "       [0.00131238],\n",
       "       [0.00131741],\n",
       "       [0.23302767],\n",
       "       [0.2303128 ],\n",
       "       [0.21837142],\n",
       "       [0.23714164],\n",
       "       [0.00134271],\n",
       "       [0.00132748],\n",
       "       [0.00134271],\n",
       "       [0.00133258],\n",
       "       [0.00148249],\n",
       "       [0.24693412],\n",
       "       [0.23166743],\n",
       "       [0.00132748],\n",
       "       [0.00139484],\n",
       "       [0.00132748],\n",
       "       [0.00135821],\n",
       "       [0.00130248],\n",
       "       [0.22296154],\n",
       "       [0.00157562],\n",
       "       [0.00133762],\n",
       "       [0.23302767],\n",
       "       [0.24481305],\n",
       "       [0.23370987],\n",
       "       [0.00132242],\n",
       "       [0.00144348],\n",
       "       [0.2196759 ],\n",
       "       [0.22033024],\n",
       "       [0.00132242],\n",
       "       [0.2504966 ],\n",
       "       [0.00131741],\n",
       "       [0.21902299],\n",
       "       [0.00161195],\n",
       "       [0.2562673 ],\n",
       "       [0.23098943],\n",
       "       [0.00135297],\n",
       "       [0.00142169],\n",
       "       [0.23098943],\n",
       "       [0.00132242],\n",
       "       [0.00131741],\n",
       "       [0.00147685],\n",
       "       [0.00132748],\n",
       "       [0.2512132 ],\n",
       "       [0.00131741],\n",
       "       [0.24340582],\n",
       "       [0.24200416],\n",
       "       [0.21837142],\n",
       "       [0.21772131],\n",
       "       [0.00132242],\n",
       "       [0.00132748],\n",
       "       [0.00131741],\n",
       "       [0.24060795],\n",
       "       [0.24906754],\n",
       "       [0.22963753],\n",
       "       [0.2427043 ],\n",
       "       [0.22033024],\n",
       "       [0.25772354],\n",
       "       [0.21902299],\n",
       "       [0.00131238],\n",
       "       [0.21707252],\n",
       "       [0.21902299],\n",
       "       [0.21772131],\n",
       "       [0.23098943],\n",
       "       [0.23166743],\n",
       "       [0.22033024],\n",
       "       [0.2350784 ],\n",
       "       [0.23370987],\n",
       "       [0.00131741],\n",
       "       [0.00156957],\n",
       "       [0.25265044],\n",
       "       [0.00131238],\n",
       "       [0.24481305],\n",
       "       [0.21837142],\n",
       "       [0.22963753],\n",
       "       [0.21707252],\n",
       "       [0.2378321 ],\n",
       "       [0.23439342],\n",
       "       [0.00131741],\n",
       "       [0.00133258],\n",
       "       [0.23166743],\n",
       "       [0.00132748],\n",
       "       [0.23991194],\n",
       "       [0.23439342],\n",
       "       [0.0013479 ],\n",
       "       [0.00130248],\n",
       "       [0.00146008],\n",
       "       [0.22098598],\n",
       "       [0.25265044],\n",
       "       [0.22428563],\n",
       "       [0.00131741],\n",
       "       [0.0015052 ],\n",
       "       [0.24693412],\n",
       "       [0.21772131],\n",
       "       [0.00158161],\n",
       "       [0.22362292],\n",
       "       [0.00133258],\n",
       "       [0.23921728],\n",
       "       [0.00147685],\n",
       "       [0.21707252],\n",
       "       [0.23370987],\n",
       "       [0.22829118],\n",
       "       [0.23234683],\n",
       "       [0.00133762],\n",
       "       [0.21707252],\n",
       "       [0.00143254],\n",
       "       [0.00131741],\n",
       "       [0.2196759 ],\n",
       "       [0.00130746],\n",
       "       [0.00131741],\n",
       "       [0.23645252],\n",
       "       [0.00133258],\n",
       "       [0.23439342],\n",
       "       [0.00133762],\n",
       "       [0.00133258],\n",
       "       [0.00133762],\n",
       "       [0.21837142]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "X_test_scaled"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Age  Previously_Insured\n",
       "289   0.64                   0\n",
       "754   0.33                   0\n",
       "553   0.24                   1\n",
       "286   0.24                   1\n",
       "1041  0.38                   0\n",
       "...    ...                 ...\n",
       "949   0.46                   0\n",
       "1139  0.27                   1\n",
       "926   0.26                   1\n",
       "129   0.27                   1\n",
       "1024  0.22                   0\n",
       "\n",
       "[361 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Previously_Insured</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>0.27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>0.26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>361 rows  2 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "coef,intercept=model.get_weights()\r\n",
    "coef,intercept"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[ 0.38131204],\n",
       "        [-5.359377  ]], dtype=float32),\n",
       " array([-1.3590709], dtype=float32))"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# to show how neuron works if we know weights and bias\r\n",
    "\r\n",
    "def sigmoid(x):\r\n",
    "    import math\r\n",
    "    return 1/(1+math.exp(-x))\r\n",
    "sigmoid(18)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9999999847700205"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def prediction_function(age,affordibility):\r\n",
    "    weighted_sum=coef[0]*age+coef[1]*affordibility+intercept\r\n",
    "    return sigmoid(weighted_sum)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "prediction_function(.64,0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.24693409977490557"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# to implement gradient descent from SCRATCH\r\n",
    "\r\n",
    "def log_loss(y_true,y_predicted):\r\n",
    "    epsilon=1e-15\r\n",
    "    y_predicted_new=[max(i,epsilon) for i in y_predicted]\r\n",
    "    y_predicted_new=[min(i,1-epsilon) for i in y_predicted_new]\r\n",
    "    y_predicted_new=np.array(y_predicted_new)\r\n",
    "    return -np.mean(y_true*np.log(y_predicted_new)+(1-y_true)*np.log(1-y_predicted_new))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "def sigmoid_numpy(x):\r\n",
    "    return 1/(1+np.exp(-x))\r\n",
    "\r\n",
    "sigmoid_numpy(np.array([12,0,1]))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.99999386, 0.5       , 0.73105858])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "def gradient_descent(age,affordability,y_true,epochs): #help to find optimal value of 'w' and 'b'\r\n",
    "    # w1,w2,bias\r\n",
    "    w1=w2=1\r\n",
    "    bias=0\r\n",
    "    learning_rate=.5\r\n",
    "    n=len(age)\r\n",
    "\r\n",
    "    for i in range(epochs):\r\n",
    "        weighted_sum=w1*age+w2*affordability+bias\r\n",
    "        y_predicted=sigmoid_numpy(weighted_sum)\r\n",
    "\r\n",
    "        loss=log_loss(y_true,y_predicted)\r\n",
    "\r\n",
    "        w1d=(1/n)*np.dot(np.transpose(age),(y_predicted-y_true))\r\n",
    "        # w1d=np.mean(age*(y_predicted-y_true))\r\n",
    "\r\n",
    "        w2d=(1/n)*np.dot(np.transpose(affordability),(y_predicted-y_true))\r\n",
    "        # w2d=np.mean(affordability*(y_predicted-y_true))\r\n",
    "        \r\n",
    "        bias_d=np.mean(y_predicted-y_true)\r\n",
    "\r\n",
    "        w1=w1-learning_rate*w1d\r\n",
    "        w2=w2-learning_rate*w2d\r\n",
    "        bias=bias-learning_rate*bias_d\r\n",
    "\r\n",
    "        print(f'Epoch:{i+1},  w1:{w1}, w2:{w2}, loss:{loss}')\r\n",
    "        \r\n",
    "    return w1,w2,bias\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "gradient_descent(X_train_scaled['Age'],X_train_scaled['Previously_Insured'],y_train,500)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:1,  w1:0.8931722670815012, w2:0.8213180612961857, loss:1.1677376027035697\n",
      "Epoch:2,  w1:0.8028246159095046, w2:0.6635539935874049, loss:0.94028745191894\n",
      "Epoch:3,  w1:0.7280887087052925, w2:0.5274471114199698, loss:0.7750514159481139\n",
      "Epoch:4,  w1:0.666936962219357, w2:0.41118961325601217, loss:0.6593809744022665\n",
      "Epoch:5,  w1:0.6169686724477094, w2:0.3117208342036162, loss:0.5794929527547031\n",
      "Epoch:6,  w1:0.5759577362427858, w2:0.2258627689088409, loss:0.5240112878725864\n",
      "Epoch:7,  w1:0.5420644337483611, w2:0.15086343700318272, loss:0.48482859238661014\n",
      "Epoch:8,  w1:0.5138456116186538, w2:0.0845214587368141, loss:0.4565526797359132\n",
      "Epoch:9,  w1:0.49019065096805664, w2:0.025131656155278653, loss:0.4356799618940039\n",
      "Epoch:10,  w1:0.4702466163468452, w2:-0.028615109900178008, loss:0.4199308380962959\n",
      "Epoch:11,  w1:0.4533542681950615, w2:-0.0777266170319859, loss:0.40780195716701034\n",
      "Epoch:12,  w1:0.4389988037598394, w2:-0.12298506912225987, loss:0.398283236329726\n",
      "Epoch:13,  w1:0.4267734414109375, w2:-0.16500410169428037, loss:0.39068218320810755\n",
      "Epoch:14,  w1:0.41635285612729, w2:-0.20427066983539902, loss:0.38451448941664373\n",
      "Epoch:15,  w1:0.4074738086438094, w2:-0.2411756532902016, loss:0.3794350069315313\n",
      "Epoch:16,  w1:0.3999209343889732, w2:-0.27603628550511644, loss:0.3751934423454381\n",
      "Epoch:17,  w1:0.3935162211127738, w2:-0.30911271300735005, loss:0.3716053770683333\n",
      "Epoch:18,  w1:0.38811113414367876, w2:-0.3406203384640447, loss:0.36853294995736324\n",
      "Epoch:19,  w1:0.38358065687472825, w2:-0.37073911777710544, loss:0.36587174291654345\n",
      "Epoch:20,  w1:0.37981873010780703, w2:-0.39962063829861044, loss:0.3635417219481567\n",
      "Epoch:21,  w1:0.37673472385210643, w2:-0.42739356504804354, loss:0.36148087716154376\n",
      "Epoch:22,  w1:0.37425067933146816, w2:-0.4541678743510639, loss:0.35964068970643087\n",
      "Epoch:23,  w1:0.37229913167073303, w2:-0.48003817727176445, loss:0.3579828553169849\n",
      "Epoch:24,  w1:0.3708213748854387, w2:-0.5050863529079233, loss:0.3564768852701513\n",
      "Epoch:25,  w1:0.36976606710987014, w2:-0.529383653290746, loss:0.3550983286489748\n",
      "Epoch:26,  w1:0.369088100021335, w2:-0.552992399926436, loss:0.3538274403550013\n",
      "Epoch:27,  w1:0.36874767525214547, w2:-0.5759673619208604, loss:0.35264817284397043\n",
      "Epoch:28,  w1:0.3687095443449037, w2:-0.5983568837047274, loss:0.3515474056513613\n",
      "Epoch:29,  w1:0.36894237896244414, w2:-0.6202038142567817, loss:0.35051435144553555\n",
      "Epoch:30,  w1:0.3694182456268639, w2:-0.6415462777618435, loss:0.34954009443000145\n",
      "Epoch:31,  w1:0.37011216494484167, w2:-0.66241831668738, loss:0.3486172288912493\n",
      "Epoch:32,  w1:0.3710017395830626, w2:-0.6828504315033322, loss:0.347739574179394\n",
      "Epoch:33,  w1:0.372066838548093, w2:-0.7028700361256357, loss:0.34690194849469014\n",
      "Epoch:34,  w1:0.37328932785892777, w2:-0.7225018442178793, loss:0.34609998825972194\n",
      "Epoch:35,  w1:0.3746528396662216, w2:-0.7417681984360429, loss:0.34533000307877676\n",
      "Epoch:36,  w1:0.37614257340813917, w2:-0.760689352327729, loss:0.34458885866271377\n",
      "Epoch:37,  w1:0.3777451238009383, w2:-0.7792837127373061, loss:0.3438738818661773\n",
      "Epoch:38,  w1:0.37944833141891177, w2:-0.797568049101308, loss:0.3431827833106447\n",
      "Epoch:39,  w1:0.3812411523802257, w2:-0.8155576748540988, loss:0.3425135940695879\n",
      "Epoch:40,  w1:0.38311354426565153, w2:-0.8332666052342501, loss:0.3418646136555468\n",
      "Epoch:41,  w1:0.3850563658890305, w2:-0.8507076950357473, loss:0.3412343671342449\n",
      "Epoch:42,  w1:0.3870612889366886, w2:-0.8678927592456795, loss:0.3406215696425483\n",
      "Epoch:43,  w1:0.38912071981733515, w2:-0.884832679021219, loss:0.3400250969377574\n",
      "Epoch:44,  w1:0.3912277303292835, w2:-0.9015374950600654, loss:0.33944396087959977\n",
      "Epoch:45,  w1:0.39337599596986395, w2:-0.9180164900919308, loss:0.33887728896139674\n",
      "Epoch:46,  w1:0.39555974089188217, w2:-0.9342782619498284, loss:0.3383243071766995\n",
      "Epoch:47,  w1:0.3977736886611779, w2:-0.9503307884577205, loss:0.33778432564245514\n",
      "Epoch:48,  w1:0.4000130180935278, w2:-0.9661814851866135, loss:0.3372567265072191\n",
      "Epoch:49,  w1:0.4022733235529107, w2:-0.981837256977452, loss:0.3367409537589938\n",
      "Epoch:50,  w1:0.4045505791801944, w2:-0.9973045440005174, loss:0.33623650461652266\n",
      "Epoch:51,  w1:0.40684110659457373, w2:-1.0125893630130056, loss:0.3357429222437986\n",
      "Epoch:52,  w1:0.4091415456719808, w2:-1.0276973443853947, loss:0.3352597895729139\n",
      "Epoch:53,  w1:0.4114488280571472, w2:-1.042633765390192, loss:0.3347867240573031\n",
      "Epoch:54,  w1:0.41376015311060277, w2:-1.0574035801812895, loss:0.3343233732076071\n",
      "Epoch:55,  w1:0.41607296602994365, w2:-1.0720114468364996, loss:0.33386941078711047\n",
      "Epoch:56,  w1:0.418384937917256, w2:-1.0864617517883164, loss:0.3334245335640472\n",
      "Epoch:57,  w1:0.4206939475925164, w2:-1.1007586319272216, loss:0.33298845853484693\n",
      "Epoch:58,  w1:0.4229980649768308, w2:-1.1149059946268702, loss:0.3325609205462719\n",
      "Epoch:59,  w1:0.42529553589012153, w2:-1.1289075359103409, loss:0.33214167025591074\n",
      "Epoch:60,  w1:0.4275847681258247, w2:-1.1427667569505824, loss:0.33173047238007136\n",
      "Epoch:61,  w1:0.4298643186807398, w2:-1.1564869790756245, loss:0.3313271041861018\n",
      "Epoch:62,  w1:0.4321328820317249, w2:-1.1700713574295074, loss:0.33093135419283976\n",
      "Epoch:63,  w1:0.43438927936274974, w2:-1.1835228934228192, loss:0.33054302104848227\n",
      "Epoch:64,  w1:0.43663244865615486, w2:-1.1968444460918186, loss:0.3301619125598591\n",
      "Epoch:65,  w1:0.4388614355710212, w2:-1.2100387424720835, loss:0.3297878448510366\n",
      "Epoch:66,  w1:0.4410753850395139, w2:-1.2231083870811836, loss:0.32942064163250595\n",
      "Epoch:67,  w1:0.4432735335190717, w2:-1.2360558705948206, loss:0.3290601335650106\n",
      "Epoch:68,  w1:0.4454552018445008, w2:-1.2488835777920224, loss:0.328706157704444\n",
      "Epoch:69,  w1:0.44761978862950297, w2:-1.2615937948371574, loss:0.32835855701625066\n",
      "Epoch:70,  w1:0.4497667641720234, w2:-1.2741887159596155, loss:0.32801717994947044\n",
      "Epoch:71,  w1:0.45189566482211385, w2:-1.286670449585877, loss:0.32768188006200605\n",
      "Epoch:72,  w1:0.4540060877748476, w2:-1.2990410239732417, loss:0.3273525156899248\n",
      "Epoch:73,  w1:0.4560976862542491, w2:-1.3113023923896499, loss:0.32702894965464707\n",
      "Epoch:74,  w1:0.45817016505726704, w2:-1.323456437879711, loss:0.32671104900276693\n",
      "Epoch:75,  w1:0.4602232764295624, w2:-1.3355049776532024, loss:0.326398684774005\n",
      "Epoch:76,  w1:0.4622568162473513, w2:-1.347449767128857, loss:0.32609173179344286\n",
      "Epoch:77,  w1:0.46427062048175666, w2:-1.3592925036631716, loss:0.3257900684847407\n",
      "Epoch:78,  w1:0.4662645619241221, w2:-1.3710348299912023, loss:0.3254935767015104\n",
      "Epoch:79,  w1:0.46823854715254504, w2:-1.3826783374038296, loss:0.3252021415744221\n",
      "Epoch:80,  w1:0.47019251372151705, w2:-1.3942245686837345, loss:0.32491565137196404\n",
      "Epoch:81,  w1:0.47212642755803613, w2:-1.4056750208203224, loss:0.32463399737307513\n",
      "Epoch:82,  w1:0.47404028054889796, w2:-1.4170311475220083, loss:0.3243570737501195\n",
      "Epoch:83,  w1:0.47593408830509043, w2:-1.4282943615426418, loss:0.32408477746088954\n",
      "Epoch:84,  w1:0.4778078880903251, w2:-1.439466036837368, loss:0.32381700814851067\n",
      "Epoch:85,  w1:0.4796617369017505, w2:-1.4505475105618781, loss:0.32355366804827923\n",
      "Epoch:86,  w1:0.4814957096918145, w2:-1.4615400849277915, loss:0.32329466190060147\n",
      "Epoch:87,  w1:0.4833098977210867, w2:-1.4724450289258064, loss:0.323039896869318\n",
      "Epoch:88,  w1:0.4851044070326242, w2:-1.4832635799272598, loss:0.3227892824647988\n",
      "Epoch:89,  w1:0.4868793570391707, w2:-1.493996945173826, loss:0.3225427304712805\n",
      "Epoch:90,  w1:0.4886348792151284, w2:-1.5046463031642594, loss:0.3223001548779889\n",
      "Epoch:91,  w1:0.49037111588583915, w2:-1.5152128049463363, loss:0.3220614718136549\n",
      "Epoch:92,  w1:0.49208821910725775, w2:-1.5256975753214614, loss:0.32182659948408693\n",
      "Epoch:93,  w1:0.493786349629606, w2:-1.5361017139687885, loss:0.3215954581125049\n",
      "Epoch:94,  w1:0.49546567593906127, w2:-1.5464262964951285, loss:0.3213679698823857\n",
      "Epoch:95,  w1:0.4971263733719606, w2:-1.5566723754164036, loss:0.32114405888260233\n",
      "Epoch:96,  w1:0.49876862329639815, w2:-1.5668409810759298, loss:0.3209236510546648\n",
      "Epoch:97,  w1:0.5003926123564592, w2:-1.5769331225043801, loss:0.320706674141902\n",
      "Epoch:98,  w1:0.5019985317746698, w2:-1.5869497882258778, loss:0.32049305764043867\n",
      "Epoch:99,  w1:0.503586576708558, w2:-1.5968919470143161, loss:0.3202827327518457\n",
      "Epoch:100,  w1:0.5051569456575051, w2:-1.6067605486036618, loss:0.3200756323373527\n",
      "Epoch:101,  w1:0.5067098399163409, w2:-1.6165565243556992, loss:0.31987169087352846\n",
      "Epoch:102,  w1:0.5082454630723783, w2:-1.6262807878883947, loss:0.3196708444093443\n",
      "Epoch:103,  w1:0.5097640205428186, w2:-1.6359342356678037, loss:0.3194730305245479\n",
      "Epoch:104,  w1:0.5112657191496677, w2:-1.645517747566211, loss:0.3192781882892785\n",
      "Epoch:105,  w1:0.5127507667295057, w2:-1.6550321873889804, loss:0.31908625822486786\n",
      "Epoch:106,  w1:0.5142193717756329, w2:-1.6644784033723923, loss:0.31889718226577296\n",
      "Epoch:107,  w1:0.5156717431102898, w2:-1.6738572286545694, loss:0.31871090372259164\n",
      "Epoch:108,  w1:0.5171080895848048, w2:-1.6831694817214229, loss:0.3185273672461205\n",
      "Epoch:109,  w1:0.518528619805673, w2:-1.6924159668294005, loss:0.3183465187924154\n",
      "Epoch:110,  w1:0.5199335418847062, w2:-1.7015974744066789, loss:0.31816830558881626\n",
      "Epoch:111,  w1:0.5213230632115219, w2:-1.7107147814343127, loss:0.31799267610090703\n",
      "Epoch:112,  w1:0.5226973902467593, w2:-1.719768651808737, loss:0.3178195800003772\n",
      "Epoch:113,  w1:0.5240567283345198, w2:-1.7287598366869088, loss:0.3176489681337568\n",
      "Epoch:114,  w1:0.5254012815326328, w2:-1.7376890748152767, loss:0.31748079249199945\n",
      "Epoch:115,  w1:0.5267312524594451, w2:-1.7465570928436722, loss:0.3173150061808871\n",
      "Epoch:116,  w1:0.5280468421559201, w2:-1.7553646056251364, loss:0.3171515633922325\n",
      "Epoch:117,  w1:0.5293482499619168, w2:-1.7641123165026145, loss:0.31699041937585765\n",
      "Epoch:118,  w1:0.5306356734055964, w2:-1.7728009175833814, loss:0.3168315304123259\n",
      "Epoch:119,  w1:0.5319093081049779, w2:-1.7814310900019947, loss:0.31667485378640703\n",
      "Epoch:120,  w1:0.5331693476807288, w2:-1.7900035041725115, loss:0.3165203477612556\n",
      "Epoch:121,  w1:0.5344159836793417, w2:-1.7985188200306503, loss:0.31636797155328344\n",
      "Epoch:122,  w1:0.5356494055059082, w2:-1.8069776872665264, loss:0.3162176853077082\n",
      "Epoch:123,  w1:0.5368698003657508, w2:-1.8153807455485444, loss:0.31606945007475823\n",
      "Epoch:124,  w1:0.5380773532142299, w2:-1.8237286247389854, loss:0.3159232277865186\n",
      "Epoch:125,  w1:0.5392722467140876, w2:-1.8320219451017872, loss:0.31577898123440046\n",
      "Epoch:126,  w1:0.5404546611997352, w2:-1.840261317502981, loss:0.31563667404721724\n",
      "Epoch:127,  w1:0.5416247746479321, w2:-1.848447343604211, loss:0.31549627066985136\n",
      "Epoch:128,  w1:0.5427827626543433, w2:-1.8565806160497342, loss:0.3153577363424967\n",
      "Epoch:129,  w1:0.5439287984154967, w2:-1.8646617186472658, loss:0.3152210370804616\n",
      "Epoch:130,  w1:0.5450630527156981, w2:-1.8726912265430145, loss:0.31508613965451604\n",
      "Epoch:131,  w1:0.5461856939184899, w2:-1.8806697063912208, loss:0.3149530115717711\n",
      "Epoch:132,  w1:0.5472968879622702, w2:-1.8885977165184944, loss:0.31482162105707423\n",
      "Epoch:133,  w1:0.5483967983597158, w2:-1.8964758070832213, loss:0.3146919370349082\n",
      "Epoch:134,  w1:0.5494855862006786, w2:-1.9043045202302957, loss:0.3145639291117792\n",
      "Epoch:135,  w1:0.5505634101582472, w2:-1.9120843902414124, loss:0.31443756755908103\n",
      "Epoch:136,  w1:0.5516304264976893, w2:-1.9198159436811373, loss:0.3143128232964243\n",
      "Epoch:137,  w1:0.552686789088009, w2:-1.9274996995389615, loss:0.3141896678754146\n",
      "Epoch:138,  w1:0.5537326494158734, w2:-1.9351361693675304, loss:0.3140680734638717\n",
      "Epoch:139,  w1:0.5547681566016827, w2:-1.9427258574172217, loss:0.31394801283047424\n",
      "Epoch:140,  w1:0.555793457417569, w2:-1.9502692607672407, loss:0.3138294593298198\n",
      "Epoch:141,  w1:0.5568086963071319, w2:-1.957766869453386, loss:0.31371238688789\n",
      "Epoch:142,  w1:0.5578140154067265, w2:-1.96521916659263, loss:0.3135967699879067\n",
      "Epoch:143,  w1:0.5588095545681386, w2:-1.9726266285046474, loss:0.31348258365657217\n",
      "Epoch:144,  w1:0.5597954513824905, w2:-1.9799897248304223, loss:0.31336980345067894\n",
      "Epoch:145,  w1:0.5607718412052338, w2:-1.987308918648046, loss:0.3132584054440824\n",
      "Epoch:146,  w1:0.5617388571820976, w2:-1.9945846665858193, loss:0.31314836621502334\n",
      "Epoch:147,  w1:0.5626966302758691, w2:-2.0018174189327653, loss:0.3130396628337927\n",
      "Epoch:148,  w1:0.5636452892938931, w2:-2.009007619746645, loss:0.3129322728507283\n",
      "Epoch:149,  w1:0.5645849609161873, w2:-2.016155706959571, loss:0.31282617428453335\n",
      "Epoch:150,  w1:0.5655157697240761, w2:-2.023262112481302, loss:0.31272134561091036\n",
      "Epoch:151,  w1:0.5664378382292563, w2:-2.0303272623003066, loss:0.3126177657514978\n",
      "Epoch:152,  w1:0.5673512869032106, w2:-2.037351576582662, loss:0.3125154140631044\n",
      "Epoch:153,  w1:0.5682562342068974, w2:-2.044335469768868, loss:0.31241427032723185\n",
      "Epoch:154,  w1:0.5691527966206463, w2:-2.0512793506686404, loss:0.31231431473987586\n",
      "Epoch:155,  w1:0.5700410886741962, w2:-2.0581836225537504, loss:0.31221552790160073\n",
      "Epoch:156,  w1:0.5709212229768202, w2:-2.0650486832489685, loss:0.3121178908078778\n",
      "Epoch:157,  w1:0.5717933102474829, w2:-2.071874925221173, loss:0.31202138483968084\n",
      "Epoch:158,  w1:0.5726574593449826, w2:-2.078662735666674, loss:0.31192599175433067\n",
      "Epoch:159,  w1:0.5735137772980354, w2:-2.08541249659681, loss:0.3118316936765836\n",
      "Epoch:160,  w1:0.5743623693352602, w2:-2.092124584921864, loss:0.3117384730899546\n",
      "Epoch:161,  w1:0.5752033389150283, w2:-2.098799372533341, loss:0.3116463128282703\n",
      "Epoch:162,  w1:0.576036787755146, w2:-2.105437226384664, loss:0.3115551960674441\n",
      "Epoch:163,  w1:0.5768628158623399, w2:-2.1120385085703153, loss:0.3114651063174683\n",
      "Epoch:164,  w1:0.5776815215615173, w2:-2.1186035764034776, loss:0.31137602741461634\n",
      "Epoch:165,  w1:0.5784930015247791, w2:-2.1251327824922064, loss:0.31128794351384936\n",
      "Epoch:166,  w1:0.5792973508001629, w2:-2.1316264748141727, loss:0.31120083908142104\n",
      "Epoch:167,  w1:0.5800946628400969, w2:-2.13808499679001, loss:0.3111146988876765\n",
      "Epoch:168,  w1:0.5808850295295485, w2:-2.1445086873553048, loss:0.31102950800003754\n",
      "Epoch:169,  w1:0.5816685412138509, w2:-2.1508978810312547, loss:0.31094525177617094\n",
      "Epoch:170,  w1:0.5824452867261963, w2:-2.1572529079940366, loss:0.3108619158573341\n",
      "Epoch:171,  w1:0.5832153534147829, w2:-2.163574094142905, loss:0.31077948616189216\n",
      "Epoch:172,  w1:0.5839788271696058, w2:-2.169861761167055, loss:0.3106979488790029\n",
      "Epoch:173,  w1:0.5847357924488841, w2:-2.1761162266112786, loss:0.31061729046246517\n",
      "Epoch:174,  w1:0.5854863323051155, w2:-2.1823378039404355, loss:0.31053749762472316\n",
      "Epoch:175,  w1:0.5862305284107545, w2:-2.1885268026027753, loss:0.310458557331027\n",
      "Epoch:176,  w1:0.586968461083507, w2:-2.1946835280921233, loss:0.31038045679374116\n",
      "Epoch:177,  w1:0.5877002093112388, w2:-2.2008082820089645, loss:0.3103031834667984\n",
      "Epoch:178,  w1:0.5884258507764955, w2:-2.206901362120444, loss:0.3102267250402951\n",
      "Epoch:179,  w1:0.5891454618806299, w2:-2.2129630624193095, loss:0.3101510694352237\n",
      "Epoch:180,  w1:0.589859117767538, w2:-2.218993673181816, loss:0.31007620479833886\n",
      "Epoch:181,  w1:0.5905668923470012, w2:-2.224993481024614, loss:0.31000211949715256\n",
      "Epoch:182,  w1:0.591268858317636, w2:-2.2309627689606457, loss:0.3099288021150564\n",
      "Epoch:183,  w1:0.5919650871894507, w2:-2.236901816454065, loss:0.30985624144656565\n",
      "Epoch:184,  w1:0.5926556493060126, w2:-2.242810899474201, loss:0.30978442649268334\n",
      "Epoch:185,  w1:0.5933406138662246, w2:-2.24869029054859, loss:0.3097133464563793\n",
      "Epoch:186,  w1:0.5940200489457164, w2:-2.254540258815087, loss:0.3096429907381833\n",
      "Epoch:187,  w1:0.5946940215178498, w2:-2.26036107007308, loss:0.3095733489318867\n",
      "Epoch:188,  w1:0.5953625974743445, w2:-2.2661529868338204, loss:0.3095044108203509\n",
      "Epoch:189,  w1:0.596025841645525, w2:-2.271916268369894, loss:0.3094361663714207\n",
      "Epoch:190,  w1:0.5966838178201935, w2:-2.277651170763839, loss:0.309368605733937\n",
      "Epoch:191,  w1:0.5973365887651328, w2:-2.2833579469559377, loss:0.3093017192338489\n",
      "Epoch:192,  w1:0.5979842162442428, w2:-2.289036846791188, loss:0.30923549737041994\n",
      "Epoch:193,  w1:0.598626761037315, w2:-2.294688117065481, loss:0.30916993081252914\n",
      "Epoch:194,  w1:0.5992642829584502, w2:-2.30031200157099, loss:0.30910501039506044\n",
      "Epoch:195,  w1:0.5998968408741233, w2:-2.3059087411407893, loss:0.3090407271153811\n",
      "Epoch:196,  w1:0.6005244927209, w2:-2.311478573692723, loss:0.308977072129906\n",
      "Epoch:197,  w1:0.6011472955228115, w2:-2.317021734272526, loss:0.30891403675074414\n",
      "Epoch:198,  w1:0.6017653054083903, w2:-2.3225384550962236, loss:0.30885161244242665\n",
      "Epoch:199,  w1:0.6023785776273741, w2:-2.3280289655918143, loss:0.3087897908187141\n",
      "Epoch:200,  w1:0.6029871665670818, w2:-2.333493492440253, loss:0.30872856363947987\n",
      "Epoch:201,  w1:0.6035911257684673, w2:-2.3389322596157456, loss:0.30866792280766814\n",
      "Epoch:202,  w1:0.6041905079418559, w2:-2.344345488425373, loss:0.3086078603663255\n",
      "Epoch:203,  w1:0.6047853649823697, w2:-2.3497333975480474, loss:0.3085483684957016\n",
      "Epoch:204,  w1:0.6053757479850455, w2:-2.3550962030728213, loss:0.308489439510421\n",
      "Epoch:205,  w1:0.6059617072596524, w2:-2.3604341185365585, loss:0.30843106585672003\n",
      "Epoch:206,  w1:0.6065432923452133, w2:-2.3657473549609773, loss:0.30837324010974926\n",
      "Epoch:207,  w1:0.6071205520242356, w2:-2.3710361208890793, loss:0.30831595497094105\n",
      "Epoch:208,  w1:0.607693534336657, w2:-2.376300622420974, loss:0.308259203265437\n",
      "Epoch:209,  w1:0.6082622865935106, w2:-2.3815410632491094, loss:0.30820297793957696\n",
      "Epoch:210,  w1:0.6088268553903161, w2:-2.3867576446929224, loss:0.30814727205844616\n",
      "Epoch:211,  w1:0.6093872866202009, w2:-2.3919505657329156, loss:0.3080920788034796\n",
      "Epoch:212,  w1:0.6099436254867563, w2:-2.3971200230441734, loss:0.30803739147012227\n",
      "Epoch:213,  w1:0.610495916516635, w2:-2.402266211029326, loss:0.3079832034655434\n",
      "Epoch:214,  w1:0.6110442035718937, w2:-2.4073893218509737, loss:0.30792950830640353\n",
      "Epoch:215,  w1:0.6115885298620864, w2:-2.4124895454635777, loss:0.307876299616673\n",
      "Epoch:216,  w1:0.6121289379561133, w2:-2.4175670696448295, loss:0.307823571125501\n",
      "Epoch:217,  w1:0.6126654697938299, w2:-2.4226220800265077, loss:0.30777131666513263\n",
      "Epoch:218,  w1:0.6131981666974213, w2:-2.427654760124831, loss:0.30771953016887416\n",
      "Epoch:219,  w1:0.6137270693825467, w2:-2.4326652913703164, loss:0.30766820566910463\n",
      "Epoch:220,  w1:0.6142522179692577, w2:-2.4376538531371517, loss:0.30761733729533247\n",
      "Epoch:221,  w1:0.6147736519926963, w2:-2.4426206227720906, loss:0.3075669192722957\n",
      "Epoch:222,  w1:0.6152914104135768, w2:-2.447565775622881, loss:0.3075169459181058\n",
      "Epoch:223,  w1:0.6158055316284551, w2:-2.4524894850662293, loss:0.3074674116424335\n",
      "Epoch:224,  w1:0.6163160534797905, w2:-2.457391922535316, loss:0.307418310944734\n",
      "Epoch:225,  w1:0.6168230132658052, w2:-2.4622732575468658, loss:0.3073696384125134\n",
      "Epoch:226,  w1:0.6173264477501439, w2:-2.467133657727781, loss:0.30732138871963344\n",
      "Epoch:227,  w1:0.6178263931713387, w2:-2.4719732888413484, loss:0.30727355662465317\n",
      "Epoch:228,  w1:0.6183228852520838, w2:-2.476792314813021, loss:0.30722613696920886\n",
      "Epoch:229,  w1:0.6188159592083227, w2:-2.481590897755792, loss:0.30717912467642833\n",
      "Epoch:230,  w1:0.6193056497581532, w2:-2.486369197995158, loss:0.30713251474938164\n",
      "Epoch:231,  w1:0.6197919911305532, w2:-2.491127374093684, loss:0.3070863022695649\n",
      "Epoch:232,  w1:0.6202750170739315, w2:-2.4958655828751795, loss:0.3070404823954178\n",
      "Epoch:233,  w1:0.6207547608645072, w2:-2.500583979448484, loss:0.3069950503608735\n",
      "Epoch:234,  w1:0.6212312553145206, w2:-2.505282717230879, loss:0.30695000147394036\n",
      "Epoch:235,  w1:0.6217045327802813, w2:-2.509961947971126, loss:0.3069053311153142\n",
      "Epoch:236,  w1:0.622174625170054, w2:-2.51462182177214, loss:0.3068610347370211\n",
      "Epoch:237,  w1:0.6226415639517885, w2:-2.519262487113303, loss:0.3068171078610891\n",
      "Epoch:238,  w1:0.6231053801606947, w2:-2.523884090872426, loss:0.30677354607824936\n",
      "Epoch:239,  w1:0.6235661044066676, w2:-2.528486778347365, loss:0.30673034504666397\n",
      "Epoch:240,  w1:0.6240237668815646, w2:-2.5330706932772955, loss:0.30668750049068266\n",
      "Epoch:241,  w1:0.6244783973663386, w2:-2.5376359778636544, loss:0.30664500819962504\n",
      "Epoch:242,  w1:0.6249300252380303, w2:-2.5421827727907496, loss:0.30660286402658893\n",
      "Epoch:243,  w1:0.6253786794766221, w2:-2.5467112172460515, loss:0.30656106388728466\n",
      "Epoch:244,  w1:0.6258243886717564, w2:-2.551221448940164, loss:0.3065196037588933\n",
      "Epoch:245,  w1:0.6262671810293231, w2:-2.5557136041264856, loss:0.3064784796789498\n",
      "Epoch:246,  w1:0.626707084377916, w2:-2.560187817620562, loss:0.30643768774424934\n",
      "Epoch:247,  w1:0.6271441261751638, w2:-2.564644222819139, loss:0.3063972241097766\n",
      "Epoch:248,  w1:0.6275783335139365, w2:-2.569082951718922, loss:0.3063570849876576\n",
      "Epoch:249,  w1:0.6280097331284312, w2:-2.5735041349350394, loss:0.3063172666461339\n",
      "Epoch:250,  w1:0.6284383514001386, w2:-2.5779079017192243, loss:0.3062777654085574\n",
      "Epoch:251,  w1:0.6288642143636938, w2:-2.582294379977715, loss:0.30623857765240686\n",
      "Epoch:252,  w1:0.6292873477126135, w2:-2.5866636962888787, loss:0.3061996998083241\n",
      "Epoch:253,  w1:0.629707776804922, w2:-2.5910159759205635, loss:0.30616112835917103\n",
      "Epoch:254,  w1:0.6301255266686683, w2:-2.5953513428471857, loss:0.30612285983910514\n",
      "Epoch:255,  w1:0.6305406220073368, w2:-2.599669919766554, loss:0.306084890832675\n",
      "Epoch:256,  w1:0.6309530872051544, w2:-2.603971828116436, loss:0.3060472179739333\n",
      "Epoch:257,  w1:0.6313629463322943, w2:-2.608257188090872, loss:0.3060098379455694\n",
      "Epoch:258,  w1:0.6317702231499814, w2:-2.6125261186562407, loss:0.30597274747805775\n",
      "Epoch:259,  w1:0.6321749411154998, w2:-2.61677873756708, loss:0.3059359433488257\n",
      "Epoch:260,  w1:0.6325771233871036, w2:-2.6210151613816657, loss:0.3058994223814366\n",
      "Epoch:261,  w1:0.6329767928288361, w2:-2.625235505477358, loss:0.3058631814447902\n",
      "Epoch:262,  w1:0.6333739720152557, w2:-2.6294398840657123, loss:0.30582721745233915\n",
      "Epoch:263,  w1:0.6337686832360733, w2:-2.633628410207362, loss:0.30579152736132076\n",
      "Epoch:264,  w1:0.6341609485007016, w2:-2.6378011958266807, loss:0.30575610817200516\n",
      "Epoch:265,  w1:0.6345507895427187, w2:-2.6419583517262173, loss:0.30572095692695744\n",
      "Epoch:266,  w1:0.6349382278242476, w2:-2.6460999876009206, loss:0.3056860707103153\n",
      "Epoch:267,  w1:0.6353232845402534, w2:-2.650226212052148, loss:0.3056514466470809\n",
      "Epoch:268,  w1:0.6357059806227603, w2:-2.6543371326014626, loss:0.30561708190242626\n",
      "Epoch:269,  w1:0.6360863367449895, w2:-2.65843285570423, loss:0.3055829736810132\n",
      "Epoch:270,  w1:0.6364643733254202, w2:-2.662513486763005, loss:0.30554911922632644\n",
      "Epoch:271,  w1:0.6368401105317748, w2:-2.666579130140726, loss:0.30551551582001935\n",
      "Epoch:272,  w1:0.6372135682849305, w2:-2.670629889173708, loss:0.3054821607812734\n",
      "Epoch:273,  w1:0.6375847662627581, w2:-2.6746658661844487, loss:0.3054490514661692\n",
      "Epoch:274,  w1:0.6379537239038904, w2:-2.6786871624942408, loss:0.3054161852670712\n",
      "Epoch:275,  w1:0.6383204604114209, w2:-2.6826938784355985, loss:0.3053835596120226\n",
      "Epoch:276,  w1:0.6386849947565345, w2:-2.686686113364504, loss:0.30535117196415357\n",
      "Epoch:277,  w1:0.6390473456820721, w2:-2.6906639656724707, loss:0.30531901982109994\n",
      "Epoch:278,  w1:0.6394075317060294, w2:-2.694627532798432, loss:0.3052871007144339\n",
      "Epoch:279,  w1:0.6397655711249923, w2:-2.6985769112404543, loss:0.30525541220910485\n",
      "Epoch:280,  w1:0.6401214820175102, w2:-2.7025121965672785, loss:0.30522395190289187\n",
      "Epoch:281,  w1:0.6404752822474071, w2:-2.7064334834296955, loss:0.3051927174258659\n",
      "Epoch:282,  w1:0.6408269894670338, w2:-2.710340865571753, loss:0.3051617064398629\n",
      "Epoch:283,  w1:0.6411766211204605, w2:-2.714234435841803, loss:0.30513091663796627\n",
      "Epoch:284,  w1:0.6415241944466129, w2:-2.7181142862033862, loss:0.30510034574399997\n",
      "Epoch:285,  w1:0.6418697264823511, w2:-2.7219805077459602, loss:0.30506999151203074\n",
      "Epoch:286,  w1:0.6422132340654939, w2:-2.7258331906954725, loss:0.3050398517258798\n",
      "Epoch:287,  w1:0.6425547338377889, w2:-2.7296724244247814, loss:0.3050099241986437\n",
      "Epoch:288,  w1:0.6428942422478294, w2:-2.7334982974639273, loss:0.3049802067722248\n",
      "Epoch:289,  w1:0.6432317755539201, w2:-2.7373108975102554, loss:0.3049506973168693\n",
      "Epoch:290,  w1:0.6435673498268911, w2:-2.741110311438395, loss:0.3049213937307153\n",
      "Epoch:291,  w1:0.6439009809528632, w2:-2.7448966253100946, loss:0.3048922939393485\n",
      "Epoch:292,  w1:0.6442326846359635, w2:-2.748669924383918, loss:0.3048633958953663\n",
      "Epoch:293,  w1:0.6445624764009936, w2:-2.7524302931248013, loss:0.3048346975779502\n",
      "Epoch:294,  w1:0.6448903715960513, w2:-2.7561778152134746, loss:0.3048061969924456\n",
      "Epoch:295,  w1:0.6452163853951057, w2:-2.759912573555751, loss:0.30477789216995044\n",
      "Epoch:296,  w1:0.6455405328005278, w2:-2.763634650291682, loss:0.3047497811669101\n",
      "Epoch:297,  w1:0.6458628286455773, w2:-2.767344126804586, loss:0.30472186206472057\n",
      "Epoch:298,  w1:0.6461832875968455, w2:-2.7710410837299473, loss:0.3046941329693387\n",
      "Epoch:299,  w1:0.6465019241566566, w2:-2.7747256009641923, loss:0.30466659201089974\n",
      "Epoch:300,  w1:0.6468187526654271, w2:-2.77839775767334, loss:0.30463923734334136\n",
      "Epoch:301,  w1:0.6471337873039844, w2:-2.7820576323015342, loss:0.3046120671440352\n",
      "Epoch:302,  w1:0.6474470420958462, w2:-2.785705302579453, loss:0.3045850796134244\n",
      "Epoch:303,  w1:0.6477585309094603, w2:-2.7893408455326045, loss:0.30455827297466825\n",
      "Epoch:304,  w1:0.6480682674604061, w2:-2.792964337489504, loss:0.3045316454732931\n",
      "Epoch:305,  w1:0.6483762653135589, w2:-2.79657585408974, loss:0.30450519537684917\n",
      "Epoch:306,  w1:0.6486825378852168, w2:-2.8001754702919275, loss:0.3044789209745743\n",
      "Epoch:307,  w1:0.6489870984451926, w2:-2.8037632603815497, loss:0.30445282057706274\n",
      "Epoch:308,  w1:0.6492899601188691, w2:-2.8073392979786944, loss:0.30442689251594096\n",
      "Epoch:309,  w1:0.6495911358892202, w2:-2.810903656045681, loss:0.30440113514354816\n",
      "Epoch:310,  w1:0.6498906385987985, w2:-2.8144564068945845, loss:0.30437554683262336\n",
      "Epoch:311,  w1:0.6501884809516884, w2:-2.817997622194656, loss:0.3043501259759973\n",
      "Epoch:312,  w1:0.6504846755154277, w2:-2.8215273729796393, loss:0.30432487098629035\n",
      "Epoch:313,  w1:0.6507792347228963, w2:-2.8250457296549922, loss:0.3042997802956156\n",
      "Epoch:314,  w1:0.6510721708741741, w2:-2.828552762005004, loss:0.3042748523552866\n",
      "Epoch:315,  w1:0.6513634961383671, w2:-2.8320485391998207, loss:0.3042500856355316\n",
      "Epoch:316,  w1:0.6516532225554039, w2:-2.8355331298023705, loss:0.304225478625211\n",
      "Epoch:317,  w1:0.651941362037803, w2:-2.8390066017752, loss:0.3042010298315414\n",
      "Epoch:318,  w1:0.6522279263724093, w2:-2.8424690224872133, loss:0.3041767377798231\n",
      "Epoch:319,  w1:0.6525129272221044, w2:-2.8459204587203244, loss:0.3041526010131736\n",
      "Epoch:320,  w1:0.6527963761274864, w2:-2.849360976676017, loss:0.3041286180922644\n",
      "Epoch:321,  w1:0.6530782845085243, w2:-2.852790641981817, loss:0.3041047875950635\n",
      "Epoch:322,  w1:0.653358663666184, w2:-2.8562095196976798, loss:0.3040811081165816\n",
      "Epoch:323,  w1:0.6536375247840284, w2:-2.859617674322288, loss:0.3040575782686232\n",
      "Epoch:324,  w1:0.6539148789297918, w2:-2.863015169799269, loss:0.3040341966795411\n",
      "Epoch:325,  w1:0.6541907370569284, w2:-2.86640206952333, loss:0.3040109619939968\n",
      "Epoch:326,  w1:0.6544651100061357, w2:-2.869778436346307, loss:0.30398787287272244\n",
      "Epoch:327,  w1:0.6547380085068538, w2:-2.873144332583136, loss:0.30396492799228947\n",
      "Epoch:328,  w1:0.6550094431787405, w2:-2.8764998200177483, loss:0.3039421260448795\n",
      "Epoch:329,  w1:0.6552794245331225, w2:-2.879844959908882, loss:0.30391946573805945\n",
      "Epoch:330,  w1:0.6555479629744234, w2:-2.88317981299582, loss:0.3038969457945608\n",
      "Epoch:331,  w1:0.6558150688015698, w2:-2.8865044395040536, loss:0.30387456495206244\n",
      "Epoch:332,  w1:0.6560807522093738, w2:-2.889818899150868, loss:0.3038523219629769\n",
      "Epoch:333,  w1:0.6563450232898942, w2:-2.8931232511508584, loss:0.30383021559424056\n",
      "Epoch:334,  w1:0.6566078920337765, w2:-2.8964175542213715, loss:0.30380824462710704\n",
      "Epoch:335,  w1:0.6568693683315711, w2:-2.899701866587876, loss:0.30378640785694405\n",
      "Epoch:336,  w1:0.6571294619750313, w2:-2.902976245989265, loss:0.30376470409303424\n",
      "Epoch:337,  w1:0.6573881826583905, w2:-2.906240749683088, loss:0.30374313215837834\n",
      "Epoch:338,  w1:0.6576455399796196, w2:-2.9094954344507133, loss:0.30372169088950257\n",
      "Epoch:339,  w1:0.6579015434416651, w2:-2.9127403566024284, loss:0.3037003791362682\n",
      "Epoch:340,  w1:0.6581562024536671, w2:-2.9159755719824694, loss:0.3036791957616854\n",
      "Epoch:341,  w1:0.6584095263321594, w2:-2.919201135973988, loss:0.30365813964172916\n",
      "Epoch:342,  w1:0.6586615243022503, w2:-2.9224171035039546, loss:0.30363720966515895\n",
      "Epoch:343,  w1:0.6589122054987852, w2:-2.9256235290479977, loss:0.3036164047333407\n",
      "Epoch:344,  w1:0.6591615789674914, w2:-2.928820466635182, loss:0.3035957237600722\n",
      "Epoch:345,  w1:0.6594096536661057, w2:-2.9320079698527244, loss:0.30357516567141146\n",
      "Epoch:346,  w1:0.659656438465484, w2:-2.93518609185065, loss:0.30355472940550665\n",
      "Epoch:347,  w1:0.6599019421506945, w2:-2.93835488534639, loss:0.30353441391243097\n",
      "Epoch:348,  w1:0.6601461734220936, w2:-2.9415144026293194, loss:0.30351421815401763\n",
      "Epoch:349,  w1:0.6603891408963861, w2:-2.9446646955652396, loss:0.3034941411037\n",
      "Epoch:350,  w1:0.6606308531076692, w2:-2.9478058156008, loss:0.3034741817463521\n",
      "Epoch:351,  w1:0.66087131850846, w2:-2.950937813767869, loss:0.3034543390781336\n",
      "Epoch:352,  w1:0.6611105454707084, w2:-2.9540607406878445, loss:0.3034346121063355\n",
      "Epoch:353,  w1:0.661348542286794, w2:-2.9571746465759157, loss:0.30341499984922987\n",
      "Epoch:354,  w1:0.6615853171705086, w2:-2.960279581245266, loss:0.3033955013359211\n",
      "Epoch:355,  w1:0.6618208782580237, w2:-2.9633755941112283, loss:0.3033761156061994\n",
      "Epoch:356,  w1:0.6620552336088434, w2:-2.966462734195383, loss:0.3033568417103973\n",
      "Epoch:357,  w1:0.6622883912067434, w2:-2.96954105012961, loss:0.3033376787092479\n",
      "Epoch:358,  w1:0.6625203589606956, w2:-2.9726105901600857, loss:0.3033186256737454\n",
      "Epoch:359,  w1:0.6627511447057794, w2:-2.975671402151235, loss:0.30329968168500826\n",
      "Epoch:360,  w1:0.6629807562040797, w2:-2.9787235335896303, loss:0.30328084583414394\n",
      "Epoch:361,  w1:0.6632092011455705, w2:-2.981767031587843, loss:0.30326211722211593\n",
      "Epoch:362,  w1:0.6634364871489868, w2:-2.9848019428882493, loss:0.3032434949596132\n",
      "Epoch:363,  w1:0.6636626217626833, w2:-2.987828313866787, loss:0.3032249781669217\n",
      "Epoch:364,  w1:0.6638876124654799, w2:-2.9908461905366686, loss:0.30320656597379647\n",
      "Epoch:365,  w1:0.6641114666674957, w2:-2.993855618552044, loss:0.3031882575193384\n",
      "Epoch:366,  w1:0.6643341917109701, w2:-2.996856643211625, loss:0.30317005195187013\n",
      "Epoch:367,  w1:0.6645557948710727, w2:-2.9998493094622587, loss:0.3031519484288159\n",
      "Epoch:368,  w1:0.6647762833567008, w2:-3.002833661902463, loss:0.30313394611658195\n",
      "Epoch:369,  w1:0.6649956643112656, w2:-3.005809744785915, loss:0.3031160441904397\n",
      "Epoch:370,  w1:0.6652139448134669, w2:-3.0087776020248995, loss:0.30309824183441003\n",
      "Epoch:371,  w1:0.6654311318780572, w2:-3.0117372771937134, loss:0.30308053824114967\n",
      "Epoch:372,  w1:0.6656472324565942, w2:-3.0146888135320316, loss:0.30306293261183936\n",
      "Epoch:373,  w1:0.6658622534381823, w2:-3.0176322539482294, loss:0.30304542415607355\n",
      "Epoch:374,  w1:0.6660762016502046, w2:-3.0205676410226676, loss:0.3030280120917519\n",
      "Epoch:375,  w1:0.6662890838590435, w2:-3.0234950170109354, loss:0.3030106956449724\n",
      "Epoch:376,  w1:0.666500906770791, w2:-3.0264144238470565, loss:0.30299347404992594\n",
      "Epoch:377,  w1:0.6667116770319497, w2:-3.0293259031466557, loss:0.30297634654879296\n",
      "Epoch:378,  w1:0.6669214012301229, w2:-3.0322294962100873, loss:0.3029593123916409\n",
      "Epoch:379,  w1:0.667130085894696, w2:-3.035125244025527, loss:0.3029423708363242\n",
      "Epoch:380,  w1:0.6673377374975074, w2:-3.0380131872720275, loss:0.3029255211483846\n",
      "Epoch:381,  w1:0.6675443624535101, w2:-3.040893366322535, loss:0.30290876260095406\n",
      "Epoch:382,  w1:0.667749967121425, w2:-3.0437658212468732, loss:0.3028920944746583\n",
      "Epoch:383,  w1:0.6679545578043833, w2:-3.0466305918146905, loss:0.30287551605752244\n",
      "Epoch:384,  w1:0.6681581407505617, w2:-3.0494877174983723, loss:0.3028590266448774\n",
      "Epoch:385,  w1:0.6683607221538076, w2:-3.052337237475918, loss:0.30284262553926833\n",
      "Epoch:386,  w1:0.6685623081542561, w2:-3.0551791906337873, loss:0.3028263120503637\n",
      "Epoch:387,  w1:0.6687629048389384, w2:-3.058013615569709, loss:0.3028100854948666\n",
      "Epoch:388,  w1:0.6689625182423814, w2:-3.0608405505954592, loss:0.30279394519642633\n",
      "Epoch:389,  w1:0.6691611543471999, w2:-3.0636600337396076, loss:0.3027778904855525\n",
      "Epoch:390,  w1:0.6693588190846796, w2:-3.06647210275023, loss:0.30276192069952895\n",
      "Epoch:391,  w1:0.669555518335353, w2:-3.0692767950975903, loss:0.30274603518233023\n",
      "Epoch:392,  w1:0.6697512579295666, w2:-3.0720741479767892, loss:0.30273023328453863\n",
      "Epoch:393,  w1:0.6699460436480411, w2:-3.074864198310387, loss:0.30271451436326263\n",
      "Epoch:394,  w1:0.6701398812224237, w2:-3.07764698275099, loss:0.3026988777820564\n",
      "Epoch:395,  w1:0.6703327763358327, w2:-3.0804225376838117, loss:0.3026833229108405\n",
      "Epoch:396,  w1:0.6705247346233945, w2:-3.083190899229201, loss:0.30266784912582384\n",
      "Epoch:397,  w1:0.6707157616727741, w2:-3.0859521032451442, loss:0.30265245580942673\n",
      "Epoch:398,  w1:0.6709058630246981, w2:-3.088706185329737, loss:0.3026371423502051\n",
      "Epoch:399,  w1:0.6710950441734702, w2:-3.0914531808236267, loss:0.3026219081427754\n",
      "Epoch:400,  w1:0.6712833105674803, w2:-3.0941931248124286, loss:0.30260675258774133\n",
      "Epoch:401,  w1:0.6714706676097064, w2:-3.096926052129114, loss:0.3025916750916209\n",
      "Epoch:402,  w1:0.6716571206582107, w2:-3.0996519973563714, loss:0.3025766750667749\n",
      "Epoch:403,  w1:0.6718426750266273, w2:-3.102370994828939, loss:0.30256175193133644\n",
      "Epoch:404,  w1:0.6720273359846455, w2:-3.1050830786359125, loss:0.30254690510914134\n",
      "Epoch:405,  w1:0.6722111087584849, w2:-3.107788282623028, loss:0.3025321340296593\n",
      "Epoch:406,  w1:0.6723939985313655, w2:-3.1104866403949147, loss:0.30251743812792675\n",
      "Epoch:407,  w1:0.6725760104439708, w2:-3.113178185317327, loss:0.3025028168444798\n",
      "Epoch:408,  w1:0.672757149594905, w2:-3.1158629505193467, loss:0.30248826962528874\n",
      "Epoch:409,  w1:0.6729374210411443, w2:-3.118540968895566, loss:0.30247379592169327\n",
      "Epoch:410,  w1:0.6731168297984825, w2:-3.1212122731082403, loss:0.3024593951903383\n",
      "Epoch:411,  w1:0.6732953808419699, w2:-3.123876895589422, loss:0.30244506689311174\n",
      "Epoch:412,  w1:0.6734730791063475, w2:-3.1265348685430645, loss:0.3024308104970815\n",
      "Epoch:413,  w1:0.6736499294864747, w2:-3.1291862239471095, loss:0.30241662547443476\n",
      "Epoch:414,  w1:0.6738259368377523, w2:-3.131830993555546, loss:0.30240251130241763\n",
      "Epoch:415,  w1:0.6740011059765388, w2:-3.1344692089004487, loss:0.30238846746327563\n",
      "Epoch:416,  w1:0.6741754416805629, w2:-3.1371009012939917, loss:0.3023744934441946\n",
      "Epoch:417,  w1:0.6743489486893289, w2:-3.139726101830444, loss:0.30236058873724325\n",
      "Epoch:418,  w1:0.6745216317045186, w2:-3.142344841388138, loss:0.302346752839316\n",
      "Epoch:419,  w1:0.6746934953903865, w2:-3.144957150631419, loss:0.3023329852520766\n",
      "Epoch:420,  w1:0.674864544374151, w2:-3.147563060012574, loss:0.30231928548190234\n",
      "Epoch:421,  w1:0.6750347832463802, w2:-3.150162599773736, loss:0.30230565303983004\n",
      "Epoch:422,  w1:0.6752042165613729, w2:-3.1527557999487716, loss:0.3022920874415012\n",
      "Epoch:423,  w1:0.6753728488375341, w2:-3.1553426903651443, loss:0.3022785882071093\n",
      "Epoch:424,  w1:0.6755406845577471, w2:-3.1579233006457597, loss:0.302265154861347\n",
      "Epoch:425,  w1:0.6757077281697392, w2:-3.160497660210789, loss:0.30225178693335436\n",
      "Epoch:426,  w1:0.6758739840864443, w2:-3.1630657982794745, loss:0.3022384839566679\n",
      "Epoch:427,  w1:0.6760394566863596, w2:-3.1656277438719136, loss:0.30222524546917\n",
      "Epoch:428,  w1:0.6762041503138989, w2:-3.1681835258108246, loss:0.30221207101303893\n",
      "Epoch:429,  w1:0.676368069279741, w2:-3.1707331727232932, loss:0.3021989601347003\n",
      "Epoch:430,  w1:0.6765312178611735, w2:-3.1732767130424997, loss:0.30218591238477843\n",
      "Epoch:431,  w1:0.6766936003024325, w2:-3.1758141750094273, loss:0.3021729273180484\n",
      "Epoch:432,  w1:0.6768552208150383, w2:-3.1783455866745536, loss:0.30216000449338926\n",
      "Epoch:433,  w1:0.6770160835781265, w2:-3.180870975899522, loss:0.3021471434737372\n",
      "Epoch:434,  w1:0.6771761927387752, w2:-3.183390370358797, loss:0.30213434382604015\n",
      "Epoch:435,  w1:0.677335552412328, w2:-3.1859037975413, loss:0.30212160512121194\n",
      "Epoch:436,  w1:0.6774941666827138, w2:-3.1884112847520276, loss:0.3021089269340884\n",
      "Epoch:437,  w1:0.6776520396027608, w2:-3.190912859113656, loss:0.3020963088433825\n",
      "Epoch:438,  w1:0.6778091751945088, w2:-3.193408547568124, loss:0.3020837504316416\n",
      "Epoch:439,  w1:0.6779655774495162, w2:-3.1958983768782, loss:0.30207125128520396\n",
      "Epoch:440,  w1:0.6781212503291638, w2:-3.1983823736290358, loss:0.3020588109941571\n",
      "Epoch:441,  w1:0.6782761977649546, w2:-3.2008605642297003, loss:0.3020464291522953\n",
      "Epoch:442,  w1:0.6784304236588105, w2:-3.203332974914698, loss:0.30203410535707886\n",
      "Epoch:443,  w1:0.6785839318833643, w2:-3.2057996317454713, loss:0.30202183920959347\n",
      "Epoch:444,  w1:0.6787367262822497, w2:-3.208260560611889, loss:0.3020096303145096\n",
      "Epoch:445,  w1:0.6788888106703862, w2:-3.2107157872337155, loss:0.3019974782800435\n",
      "Epoch:446,  w1:0.6790401888342618, w2:-3.213165337162068, loss:0.30198538271791764\n",
      "Epoch:447,  w1:0.6791908645322112, w2:-3.215609235780857, loss:0.30197334324332226\n",
      "Epoch:448,  w1:0.6793408414946918, w2:-3.21804750830821, loss:0.30196135947487757\n",
      "Epoch:449,  w1:0.6794901234245552, w2:-3.2204801797978857, loss:0.3019494310345956\n",
      "Epoch:450,  w1:0.6796387139973163, w2:-3.222907275140666, loss:0.3019375575478436\n",
      "Epoch:451,  w1:0.6797866168614191, w2:-3.2253288190657403, loss:0.3019257386433073\n",
      "Epoch:452,  w1:0.6799338356384985, w2:-3.227744836142071, loss:0.3019139739529545\n",
      "Epoch:453,  w1:0.6800803739236403, w2:-3.230155350779748, loss:0.30190226311199964\n",
      "Epoch:454,  w1:0.6802262352856369, w2:-3.2325603872313255, loss:0.30189060575886867\n",
      "Epoch:455,  w1:0.6803714232672406, w2:-3.2349599695931492, loss:0.301879001535164\n",
      "Epoch:456,  w1:0.6805159413854139, w2:-3.2373541218066673, loss:0.30186745008563026\n",
      "Epoch:457,  w1:0.6806597931315764, w2:-3.2397428676597273, loss:0.30185595105812063\n",
      "Epoch:458,  w1:0.6808029819718494, w2:-3.2421262307878624, loss:0.3018445041035631\n",
      "Epoch:459,  w1:0.6809455113472969, w2:-3.244504234675562, loss:0.3018331088759276\n",
      "Epoch:460,  w1:0.6810873846741646, w2:-3.2468769026575317, loss:0.30182176503219327\n",
      "Epoch:461,  w1:0.6812286053441156, w2:-3.2492442579199365, loss:0.30181047223231644\n",
      "Epoch:462,  w1:0.6813691767244628, w2:-3.251606323501636, loss:0.3017992301391986\n",
      "Epoch:463,  w1:0.6815091021584002, w2:-3.2539631222954046, loss:0.3017880384186553\n",
      "Epoch:464,  w1:0.6816483849652297, w2:-3.2563146770491387, loss:0.30177689673938507\n",
      "Epoch:465,  w1:0.6817870284405865, w2:-3.2586610103670535, loss:0.3017658047729385\n",
      "Epoch:466,  w1:0.6819250358566609, w2:-3.2610021447108664, loss:0.3017547621936885\n",
      "Epoch:467,  w1:0.6820624104624188, w2:-3.263338102400969, loss:0.3017437686788003\n",
      "Epoch:468,  w1:0.6821991554838186, w2:-3.265668905617587, loss:0.3017328239082018\n",
      "Epoch:469,  w1:0.6823352741240257, w2:-3.267994576401928, loss:0.3017219275645545\n",
      "Epoch:470,  w1:0.6824707695636251, w2:-3.2703151366573198, loss:0.3017110793332252\n",
      "Epoch:471,  w1:0.682605644960831, w2:-3.2726306081503345, loss:0.3017002789022571\n",
      "Epoch:472,  w1:0.6827399034516943, w2:-3.2749410125119036, loss:0.30168952596234194\n",
      "Epoch:473,  w1:0.6828735481503079, w2:-3.2772463712384208, loss:0.30167882020679254\n",
      "Epoch:474,  w1:0.6830065821490087, w2:-3.2795467056928334, loss:0.30166816133151503\n",
      "Epoch:475,  w1:0.6831390085185788, w2:-3.2818420371057244, loss:0.3016575490349824\n",
      "Epoch:476,  w1:0.6832708303084432, w2:-3.284132386576383, loss:0.3016469830182072\n",
      "Epoch:477,  w1:0.6834020505468655, w2:-3.286417775073864, loss:0.3016364629847159\n",
      "Epoch:478,  w1:0.6835326722411423, w2:-3.2886982234380366, loss:0.3016259886405224\n",
      "Epoch:479,  w1:0.6836626983777938, w2:-3.2909737523806246, loss:0.30161555969410236\n",
      "Epoch:480,  w1:0.6837921319227535, w2:-3.293244382486235, loss:0.301605175856368\n",
      "Epoch:481,  w1:0.6839209758215552, w2:-3.2955101342133766, loss:0.301594836840643\n",
      "Epoch:482,  w1:0.6840492329995187, w2:-3.297771027895467, loss:0.30158454236263754\n",
      "Epoch:483,  w1:0.6841769063619321, w2:-3.3000270837418335, loss:0.30157429214042414\n",
      "Epoch:484,  w1:0.6843039987942329, w2:-3.3022783218387017, loss:0.3015640858944133\n",
      "Epoch:485,  w1:0.6844305131621872, w2:-3.304524762150174, loss:0.30155392334732956\n",
      "Epoch:486,  w1:0.6845564523120665, w2:-3.3067664245191994, loss:0.30154380422418814\n",
      "Epoch:487,  w1:0.6846818190708227, w2:-3.3090033286685343, loss:0.3015337282522714\n",
      "Epoch:488,  w1:0.6848066162462612, w2:-3.3112354942016933, loss:0.30152369516110616\n",
      "Epoch:489,  w1:0.6849308466272117, w2:-3.3134629406038907, loss:0.30151370468244043\n",
      "Epoch:490,  w1:0.6850545129836981, w2:-3.3156856872429734, loss:0.3015037565502214\n",
      "Epoch:491,  w1:0.6851776180671053, w2:-3.317903753370344, loss:0.3014938505005731\n",
      "Epoch:492,  w1:0.685300164610345, w2:-3.3201171581218767, loss:0.30148398627177436\n",
      "Epoch:493,  w1:0.6854221553280193, w2:-3.322325920518821, loss:0.3014741636042373\n",
      "Epoch:494,  w1:0.6855435929165826, w2:-3.324530059468701, loss:0.30146438224048583\n",
      "Epoch:495,  w1:0.6856644800545021, w2:-3.3267295937662023, loss:0.30145464192513444\n",
      "Epoch:496,  w1:0.6857848194024158, w2:-3.3289245420940534, loss:0.30144494240486736\n",
      "Epoch:497,  w1:0.6859046136032892, w2:-3.3311149230238963, loss:0.30143528342841797\n",
      "Epoch:498,  w1:0.6860238652825708, w2:-3.33330075501715, loss:0.3014256647465481\n",
      "Epoch:499,  w1:0.6861425770483446, w2:-3.3354820564258656, loss:0.30141608611202825\n",
      "Epoch:500,  w1:0.6862607514914825, w2:-3.337658845493573, loss:0.3014065472796173\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.6862607514914825, -3.337658845493573, -1.5382103556936044)"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "interpreter": {
   "hash": "8551e0ab9876ec51073e0fff13c60ee316e8ca1cb46c814b591d91a5f899d8c5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}